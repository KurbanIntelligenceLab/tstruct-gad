{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404350,"status":"ok","timestamp":1722881522233,"user":{"displayName":"Samir Salam Sameer Abdaljalil","userId":"12562233440534725758"},"user_tz":-180},"id":"97FzPKFv0_HH","outputId":"2b3792c8-0a85-494d-fea5-401511409947"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: torch 2.3.1+cu121\n","Uninstalling torch-2.3.1+cu121:\n","  Would remove:\n","    /usr/local/bin/convert-caffe2-to-onnx\n","    /usr/local/bin/convert-onnx-to-caffe2\n","    /usr/local/bin/torchrun\n","    /usr/local/lib/python3.10/dist-packages/functorch/*\n","    /usr/local/lib/python3.10/dist-packages/torch-2.3.1+cu121.dist-info/*\n","    /usr/local/lib/python3.10/dist-packages/torch/*\n","    /usr/local/lib/python3.10/dist-packages/torchgen/*\n","Proceed (Y/n)? Y\n","  Successfully uninstalled torch-2.3.1+cu121\n","Collecting torch==2.1.0\n","  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.15.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0)\n","  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.1.0 (from torch==2.1.0)\n","  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0)\n","  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n","Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n","Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.3.1\n","    Uninstalling triton-2.3.1:\n","      Successfully uninstalled triton-2.3.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.1.0 which is incompatible.\n","torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.1.0 which is incompatible.\n","torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 triton-2.1.0\n","2.1.0+cu121\n"]}],"source":["!pip uninstall torch\n","!pip install torch==2.1.0\n","import torch\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11946,"status":"ok","timestamp":1722881543556,"user":{"displayName":"Samir Salam Sameer Abdaljalil","userId":"12562233440534725758"},"user_tz":-180},"id":"2rUY3uNM1IhM","outputId":"76fc637a-fc5e-4ddb-cf83-fc17a5d3854e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n","Collecting torch_scatter\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_sparse\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_cluster\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_spline_conv\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (932 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.1/932.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\n","Installing collected packages: torch_spline_conv, torch_scatter, torch_sparse, torch_cluster\n","Successfully installed torch_cluster-1.6.3+pt21cu121 torch_scatter-2.1.2+pt21cu121 torch_sparse-0.6.18+pt21cu121 torch_spline_conv-1.2.2+pt21cu121\n"]}],"source":["!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8896,"status":"ok","timestamp":1722881552449,"user":{"displayName":"Samir Salam Sameer Abdaljalil","userId":"12562233440534725758"},"user_tz":-180},"id":"Ps0KdxlY1KJx","outputId":"ad8b6717-2a42-48cd-f78b-4f5a770b2341"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pygod\n","  Downloading pygod-1.1.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.3.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pygod) (3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pygod) (71.0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.7.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pygod-1.1.0-py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric, pygod\n","Successfully installed pygod-1.1.0 torch-geometric-2.4.0\n"]}],"source":["!pip install torch-geometric==2.4.0 pygod\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26976,"status":"ok","timestamp":1722881579397,"user":{"displayName":"Samir Salam Sameer Abdaljalil","userId":"12562233440534725758"},"user_tz":-180},"id":"0u6U1wg4HvgX","outputId":"e8537944-0dc0-4f99-f1b3-42dcc598b279"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torch_geometric_temporal==0.54.0\n","  Downloading torch_geometric_temporal-0.54.0.tar.gz (48 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m41.0/48.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m832.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal==0.54.0) (4.4.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal==0.54.0) (2.1.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal==0.54.0) (3.0.10)\n","Collecting pandas<=1.3.5 (from torch_geometric_temporal==0.54.0)\n","  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal==0.54.0) (0.6.18+pt21cu121)\n","Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal==0.54.0) (2.1.2+pt21cu121)\n","Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal==0.54.0) (2.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal==0.54.0) (1.26.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal==0.54.0) (1.16.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal==0.54.0) (3.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch_geometric_temporal==0.54.0) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch_geometric_temporal==0.54.0) (2024.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (3.15.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (2024.6.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (2.18.1)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (12.1.105)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal==0.54.0) (2.1.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torch_geometric_temporal==0.54.0) (12.6.20)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal==0.54.0) (4.66.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal==0.54.0) (1.13.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal==0.54.0) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal==0.54.0) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal==0.54.0) (1.3.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal==0.54.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch_geometric_temporal==0.54.0) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch_geometric_temporal==0.54.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch_geometric_temporal==0.54.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch_geometric_temporal==0.54.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch_geometric_temporal==0.54.0) (2024.7.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch_geometric_temporal==0.54.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch_geometric_temporal==0.54.0) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch_geometric_temporal==0.54.0) (1.3.0)\n","Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: torch_geometric_temporal\n","  Building wheel for torch_geometric_temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch_geometric_temporal: filename=torch_geometric_temporal-0.54.0-py3-none-any.whl size=86713 sha256=15545fed73c62bbc1f511bf4b5bcb1ba7822c087b49999a2738344104c1d0cf1\n","  Stored in directory: /root/.cache/pip/wheels/9e/9b/b6/e15256e053f0cb49b1084a67a709db909d418386a231f0722c\n","Successfully built torch_geometric_temporal\n","Installing collected packages: pandas, torch_geometric_temporal\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.1.4\n","    Uninstalling pandas-2.1.4:\n","      Successfully uninstalled pandas-2.1.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","arviz 0.18.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n","bigframes 1.12.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n","cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.3.5 which is incompatible.\n","geopandas 0.14.4 requires pandas>=1.4.0, but you have pandas 1.3.5 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.3.5 which is incompatible.\n","plotnine 0.12.4 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n","statsmodels 0.14.2 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\n","xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pandas-1.3.5 torch_geometric_temporal-0.54.0\n"]}],"source":["!pip install torch_geometric_temporal==0.54.0\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4758,"status":"ok","timestamp":1722881584138,"user":{"displayName":"Samir Salam Sameer Abdaljalil","userId":"12562233440534725758"},"user_tz":-180},"id":"L6gtTNDS9mJC","outputId":"c4e96664-0c8b-4392-a4d0-cc3b97f1d30c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting memory_profiler\n","  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n","Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n","Installing collected packages: memory_profiler\n","Successfully installed memory_profiler-0.61.0\n"]}],"source":["!pip install memory_profiler\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QGCZgtR9_APs"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import random\n","from datetime import datetime, timedelta\n","import torch\n","import pickle\n","from torch.nn import Linear, Module, ModuleList, Sequential\n","from torch_geometric.nn import GATConv\n","import torch.nn.functional as F\n","from torch_geometric.data import DataLoader, Data\n","from torch.nn import Module, Embedding, Linear, Sequential, ReLU, LSTM\n","from torch_geometric_temporal.nn.recurrent import GConvGRU\n","import tensorflow as tf\n","from pygod.metric import eval_roc_auc, eval_f1\n","from pygod.utils import load_data\n","\n","from pygod.detector import CONAD, AdONE, ANOMALOUS, DOMINANT, DONE, GADNR, GAE, OCGNN,CoLA, SCAN, Radar, ONE, GUIDE, DMGD, AnomalyDAE, GAAN\n","import time\n","from memory_profiler import memory_usage\n","import tracemalloc\n","import gc\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0adaXrNGacu_"},"outputs":[],"source":["\n","\n","def setup_seed(seed=42):\n","    \"\"\"Sets the seed for reproducibility.\"\"\"\n","    random.seed(seed)                # Python RNG\n","    np.random.seed(seed)             # Numpy RNG\n","    torch.manual_seed(seed)          # PyTorch RNG for CPU\n","    torch.cuda.manual_seed(seed)     # PyTorch RNG for all GPU devices\n","    torch.cuda.manual_seed_all(seed) # PyTorch RNG for all GPUs (if using multiple GPUs)\n","    tf.random.set_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","\n","    torch.use_deterministic_algorithms(True)\n","\n","# Call this function at the start of your script\n","setup_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"E6jtg5tgJjmy"},"source":["# BOND Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDaPj4-x5S5N"},"outputs":[],"source":["import warnings\n","import time\n","import tracemalloc\n","\n","\n","import gc\n","from memory_profiler import memory_usage\n","\n","\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","gc.collect()\n","\n","\n","def measure_algorithm_memory(algorithm, dataset):\n","    # Explicitly run garbage collection\n","    gc.collect()\n","    # Measure memory usage of the algorithm's fit and predict methods\n","    memory_used = memory_usage((algorithm.fit, (dataset,)), interval=0.05, max_usage=True)\n","    return memory_used\n","\n","def bond_pipeline(dataset):\n","    setup_seed(42)\n","\n","    roc_scores = {}\n","    timing = {}\n","    pred_dict={}\n","    prob_dict = {}\n","    score = {}\n","    memory_consumption = {}\n","\n","    y_values = [int(value) for value in dataset.y]\n","    y_values = [1 if x == 1 else 0 for x in y_values]\n","\n","\n","    algorithms = [\n","        (\"One\", ONE()),\n","        (\"AnomalyDAE\", AnomalyDAE(save_emb=True)),\n","        (\"CONAD\", CONAD()),\n","        (\"AdONE\", AdONE()),\n","        (\"ANOMALOUS\", ANOMALOUS()),\n","        (\"CoLA\", CoLA()),\n","        (\"DOMINANT\", DOMINANT(save_emb=True)),\n","        (\"DONE\", DONE()),\n","        (\"GAE\", GAE()),\n","        (\"OCGNN\", OCGNN()),\n","        (\"SCAN\", SCAN()),\n","        (\"Radar\", Radar())\n","\n","    ]\n","\n","\n","\n","\n","# stopping the library\n","\n","\n","    for name, algorithm in algorithms:\n","\n","        gc.collect()  # Collect garbage to start fresh\n","\n","        start_memory = memory_usage()[0]  # Measure initial memory usage\n","        start_time = time.time()\n","        tracemalloc.start()\n","        # Fit the algorithm\n","        algorithm.fit(dataset)\n","        pred, score, prob = algorithm.predict(dataset, return_pred=True, return_score=True, return_prob=True, return_conf=False)\n","        if name =='AnomalyDAE':\n","          print(len(algorithm.emb))\n","        roc = eval_roc_auc(y_values, score)\n","\n","        end_time = time.time()\n","        end_memory = memory_usage()[0]  # Measure final memory usage\n","        memory_increment = end_memory - start_memory\n","\n","        roc_scores[name] = roc\n","        timing[name] = end_time - start_time\n","        pred_dict[name] = pred\n","        prob_dict[name] = prob\n","        memory_consumption[name] = tracemalloc.get_traced_memory()[-1]  # Calculate incremental memory usage\n","        tracemalloc.stop()\n","        print(f'{name}: ROC: {roc}, Time: {timing[name]}s, Memory: {memory_consumption[name]} MiB')\n","\n","    return roc_scores, pred_dict, prob_dict, timing, memory_consumption\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRr4lBk1DIK_"},"outputs":[],"source":["import pickle\n","import torch\n","import warnings\n","import time\n","import tracemalloc\n","\n","\n","import gc\n","from memory_profiler import memory_usage\n","\n","\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","def bond_embeddings(dataset,dataset_name):\n","    setup_seed(42)\n","\n","\n","\n","    algorithms = [\n","        (\"AnomalyDAE\", AnomalyDAE(save_emb=True)),\n","        (\"CONAD\", CONAD(save_emb=True)),\n","        (\"AdONE\", AdONE(save_emb=True)),\n","        (\"CoLA\", CoLA(save_emb=True)),\n","        (\"DOMINANT\", DOMINANT(save_emb=True)),\n","        (\"DONE\", DONE(save_emb=True)),\n","        (\"GAE\", GAE(save_emb=True)),\n","        (\"OCGNN\", OCGNN(save_emb=True)),\n","    ]\n","\n","\n","\n","\n","# stopping the library\n","\n","\n","    for name, algorithm in algorithms:\n","\n","        gc.collect()  # Collect garbage to start fresh\n","\n","        start_memory = memory_usage()[0]  # Measure initial memory usage\n","        start_time = time.time()\n","        tracemalloc.start()\n","        # Fit the algorithm\n","        algorithm.fit(dataset)\n","        with open(f\"{dataset_name}_{name}_node_embeddings.pkl\", \"wb\") as f:\n","            pickle.dump(algorithm.emb, f)\n","\n","\n","        print(name,'done')\n","\n","    # return"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47895,"status":"ok","timestamp":1712858803483,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"D6iUXOzKGonS","outputId":"02e79c73-05ce-46ec-c016-acc42ed7056e"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------\n","disney\n","AnomalyDAE done\n","CONAD done\n","AdONE done\n","CoLA done\n","DOMINANT done\n","DONE done\n","GAE done\n","OCGNN done\n","------------\n","books\n","AnomalyDAE done\n","CONAD done\n","AdONE done\n","CoLA done\n","DOMINANT done\n","DONE done\n","GAE done\n","OCGNN done\n"]}],"source":["setup_seed(42)\n","# datasets = ['disney','reddit','enron','weibo','books']\n","# # datasets = ['reddit','enron','weibo']\n","# datasets = ['disney','books']\n","\n","for d in datasets:\n","  dataset = load_data(d)\n","  # # print('ROC Score:', roc_score)\n","  print('------------')\n","  print(d)\n","  bond_embeddings(dataset,d)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13178982,"status":"ok","timestamp":1712823273094,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"p-wGnSGxPt3v","outputId":"19dce162-7c84-4069-dfab-0470a08c2173"},"outputs":[{"name":"stdout","output_type":"stream","text":["dgraph\n","AnomalyDAE done\n","CONAD done\n","AdONE done\n","CoLA done\n","DOMINANT done\n","DONE done\n","GAE done\n","OCGNN done\n"]}],"source":["from torch_geometric.datasets import DGraphFin\n","\n","dataset = DGraphFin(root='/data')\n","data = dataset[0]\n","\n","import torch\n","from torch_geometric.data import Data\n","\n","# Assuming 'data' is your PyTorch Geometric Data object\n","\n","# Step 1: Sort edges by 'edge_time'\n","sorted_indices = data.edge_time.argsort()\n","sorted_edge_index = data.edge_index[:, sorted_indices]\n","sorted_edge_time = data.edge_time[sorted_indices]\n","sorted_edge_type = data.edge_type[sorted_indices]\n","\n","# Step 2: Identify the first 10 unique 'edge_time' values\n","unique_edge_times = sorted_edge_time.unique()[:5]\n","\n","# Step 3: Create incremental snapshots\n","snapshots = []\n","for time in unique_edge_times:\n","    # Identify edges up to the current 'edge_time'\n","    valid_edges_mask = sorted_edge_time <= time\n","    current_edge_index = sorted_edge_index[:, valid_edges_mask]\n","    current_edge_type = sorted_edge_type[valid_edges_mask]\n","\n","    involved_nodes = current_edge_index.unique()\n","\n","    # Extract features for involved nodes\n","    current_x = data.x[involved_nodes]\n","    current_y = data.y[involved_nodes]\n","\n","    # Create a snapshot Data object\n","    snapshot = Data(x=current_x, edge_index=current_edge_index, y=current_y,\n","                    edge_type=current_edge_type, edge_time=time,\n","                    train_mask=None, val_mask=None, test_mask=None)  # Update masks as needed\n","    snapshots.append(snapshot)\n","\n","import torch\n","from torch_geometric.data import Data\n","import torch\n","import time\n","\n","def reindex_nodes(data_snapshot):\n","    \"\"\"\n","    Adjusts edge_index and x to ensure node indices are continuous and synchronized.\n","    :param data_snapshot: A Data object containing x (node features) and edge_index.\n","    :return: A new Data object with adjusted edge_index and potentially x.\n","    \"\"\"\n","    unique_nodes, new_indices = torch.unique(data_snapshot.edge_index, return_inverse=True)\n","    num_nodes = data_snapshot.x.size(0)\n","\n","    # Initialize a new x if necessary\n","    if len(unique_nodes) != num_nodes:\n","        new_x = torch.zeros((len(unique_nodes), data_snapshot.x.size(1)), dtype=data_snapshot.x.dtype)\n","        new_x[unique_nodes] = data_snapshot.x[:len(unique_nodes)]\n","    else:\n","        new_x = data_snapshot.x\n","\n","    # Reshape new_indices to match the shape of edge_index\n","    new_edge_index = new_indices.view(data_snapshot.edge_index.size())\n","\n","    return Data(x=new_x, edge_index=new_edge_index, y=data_snapshot.y if hasattr(data_snapshot, 'y') else None)\n","\n","reindexed_snapshots = [reindex_nodes(snapshot) for snapshot in snapshots]\n","\n","d='dgraph'\n","print(d)\n","bond_embeddings(reindexed_snapshots[-1],d)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2873525,"status":"ok","timestamp":1711242903061,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"Vy-NzWfB64rh","outputId":"a9e00a48-fe76-44d5-bca3-43239823fcb4"},"outputs":[],"source":["setup_seed(42)\n","datasets = ['reddit','enron','weibo']\n","\n","for d in datasets:\n","  dataset = load_data(d)\n","  print('------------')\n","  print(d)\n","  roc_scores, timing, memory_consumption = bond_pipeline(dataset)\n"]},{"cell_type":"markdown","metadata":{"id":"fA1IqxkI34JW"},"source":["# Weibo Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbi84dC2IYVo"},"outputs":[],"source":["from pygod.utils import load_data\n","dataset = load_data('weibo')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1712366168177,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"b2gsk4AY7um5","outputId":"bdf1432f-9295-46bd-f0cd-116b878d5fc1"},"outputs":[{"data":{"text/plain":["Data(x=[8405, 400], edge_index=[2, 407963], y=[8405], train_mask=[8405], test_mask=[8405], val_mask=[8405])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VbiHV74IuztL"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","import torch\n","import numpy as np\n","\n","# Assume `data` is your PyTorch Geometric Data object\n","data_features = dataset.x.numpy()  # Convert the tensor to a numpy array\n","\n","pca = PCA(n_components=0.90)\n","\n","# Fit and transform the features\n","reduced_features = pca.fit_transform(data_features)\n","\n","# Update the Data object with the reduced features\n","dataset.x = torch.tensor(reduced_features, dtype=torch.float)\n","\n","# Now `data.x` has reduced features, ready for use in your model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1712366171949,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"AeM5CB7zu5FB","outputId":"0b212c6c-819d-422f-b9b7-9d1ac1e7d815"},"outputs":[{"data":{"text/plain":["Data(x=[8405, 40], edge_index=[2, 407963], y=[8405], train_mask=[8405], test_mask=[8405], val_mask=[8405])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27926075,"status":"ok","timestamp":1712159536513,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"Pcl2oVt7RcVf","outputId":"fcb7b309-25f1-40b4-faec-3f85a6c3cadf"},"outputs":[],"source":["roc_scores, pred, prob, timing, memory_consumption = bond_pipeline(dataset)\n","\n","filename = 'data/weibo_bond_results.pkl'\n","\n","# Open the file in binary write mode and save (pickle) the dictionary\n","my_dict = {'roc_scores': roc_scores, 'pred': pred, 'prob': prob, 'timing': timing, 'memory_consumption': memory_consumption}\n","with open(filename, 'wb') as file:\n","    pickle.dump(my_dict, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8012858,"status":"ok","timestamp":1712304135790,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"w5pJbT0czRp9","outputId":"ae8ccc44-378d-4c23-fb70-a05449210f11"},"outputs":[],"source":["roc_scores, pred, prob, timing, memory_consumption = bond_pipeline(dataset)\n","\n","filename = 'data/weiboREDUCED_bond_results.pkl'\n","\n","# Open the file in binary write mode and save (pickle) the dictionary\n","my_dict = {'roc_scores': roc_scores, 'pred': pred, 'prob': prob, 'timing': timing, 'memory_consumption': memory_consumption}\n","with open(filename, 'wb') as file:\n","    pickle.dump(my_dict, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3r3noDu634f"},"outputs":[],"source":["with open('data/weibo_bond_results.pkl', 'rb') as file:\n","    weibo = pickle.load(file)\n","\n","weibo['y_true']=dataset.y\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189,"status":"ok","timestamp":1712207440433,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"5zmmffP87r89","outputId":"6780746b-0361-4cb9-8b0f-8222767fd6ad"},"outputs":[{"data":{"text/plain":["8405"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["len(dataset.y)"]},{"cell_type":"markdown","metadata":{"id":"2Yc20QNg78Py"},"source":["## TGN_Attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16lOBihXlB6h"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch_geometric.data import Data\n","from datetime import datetime, timedelta\n","setup_seed(42)\n","\n","start_date = pd.to_datetime('2011-11-09')\n","end_date = pd.to_datetime('2011-12-21')\n","date_range = (end_date - start_date).days + 1\n","num_edges = dataset.num_edges\n","num_nodes = dataset.num_nodes\n","edge_dates = np.linspace(0, date_range-1, num=num_edges, dtype=int)\n","np.random.shuffle(edge_dates)\n","labels = np.array(dataset.y)\n","\n","edge_index = torch.randint(0, num_nodes, (2, num_edges), dtype=torch.long)\n","\n","suspicious_intervals = [10, 15, 30, 45, 60]\n","adjusted_dates = []\n","suspicious_edges_count = {node: 0 for node in range(num_nodes) if labels[node] == 1}\n","\n","for i, days in enumerate(edge_dates):\n","    source, target = edge_index[:, i]\n","    if labels[source.item()] == 1 and suspicious_edges_count[source.item()] < 5:\n","        seconds_offset = np.random.choice(suspicious_intervals)\n","        # Place the next suspicious edge within the selected short interval\n","        if adjusted_dates:\n","            last_date = max(adjusted_dates)\n","            adjusted_dates.append(last_date + pd.Timedelta(seconds=seconds_offset))\n","        else:\n","            adjusted_dates.append(start_date + pd.Timedelta(days=days) + pd.Timedelta(seconds=seconds_offset))\n","        suspicious_edges_count[source.item()] += 1\n","    else:\n","        adjusted_dates.append(start_date + pd.Timedelta(days=days))\n","\n","publication_dates_edges = adjusted_dates\n","\n","def create_snapshot_dynamic_filtered(data, publication_dates_edges, start_date, end_date):\n","    snapshots_filtered = []\n","    edge_indices = torch.arange(0, data.edge_index.size(1))\n","    current_date = start_date\n","\n","    while current_date <= end_date:\n","        # Determine which edges to include in the current snapshot based on their assigned dates\n","        edge_mask = np.array([date <= current_date for date in publication_dates_edges])\n","        filtered_edge_indices = edge_indices[edge_mask]\n","\n","        if len(filtered_edge_indices) > 0:\n","            filtered_edges = data.edge_index[:, filtered_edge_indices]\n","\n","            nodes_in_snapshot = torch.unique(filtered_edges)\n","            x = data.x[nodes_in_snapshot]  # Extract node features for these nodes\n","\n","            snapshot_data = Data(x=x, edge_index=filtered_edges,edge_attr=[0])\n","            snapshots_filtered.append(snapshot_data)\n","\n","        current_date += timedelta(days=1)\n","\n","    # Ensure the last snapshot includes all nodes and edges\n","    if snapshots_filtered[-1].edge_index.size(1) < data.edge_index.size(1):\n","        # If not all edges are included by the last date, add remaining edges\n","        snapshots_filtered[-1] = data\n","\n","    return snapshots_filtered\n","\n","snapshots_dynamic_filtered = create_snapshot_dynamic_filtered(dataset, publication_dates_edges, start_date, end_date)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rFoIfXufylQG"},"outputs":[],"source":["import torch\n","from torch_geometric.data import Data\n","import torch\n","\n","def reindex_nodes(data_snapshot):\n","    \"\"\"\n","    Adjusts edge_index and x to ensure node indices are continuous and synchronized.\n","    :param data_snapshot: A Data object containing x (node features) and edge_index.\n","    :return: A new Data object with adjusted edge_index and potentially x.\n","    \"\"\"\n","    unique_nodes, new_indices = torch.unique(data_snapshot.edge_index, return_inverse=True)\n","    num_nodes = data_snapshot.x.size(0)\n","\n","    # Initialize a new x if necessary\n","    if len(unique_nodes) != num_nodes:\n","        new_x = torch.zeros((len(unique_nodes), data_snapshot.x.size(1)), dtype=data_snapshot.x.dtype)\n","        new_x[unique_nodes] = data_snapshot.x[:len(unique_nodes)]\n","    else:\n","        new_x = data_snapshot.x\n","\n","    # Reshape new_indices to match the shape of edge_index\n","    new_edge_index = new_indices.view(data_snapshot.edge_index.size())\n","\n","    return Data(x=new_x, edge_index=new_edge_index, y=data_snapshot.y if hasattr(data_snapshot, 'y') else None)\n","\n","reindexed_snapshots = [reindex_nodes(snapshot) for snapshot in snapshots_dynamic_filtered]\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iD6-nXoLAR4l"},"outputs":[],"source":["from torch_geometric.nn import GCNConv\n","num_snapshots = 0\n","for snap in reindexed_snapshots:\n","  num_snapshots+=1\n","\n","\n","node_features_dim = 400\n","hidden_dim = 200\n","\n","num_epochs = 5\n","learning_rate = 0.01\n","total_nodes = 8405  # Make sure this is the maximum number of nodes in any snapshot\n"]},{"cell_type":"markdown","metadata":{"id":"Kd-siFGp8tTd"},"source":["### TGN with simple embedding aggregation (last snapshot embedding)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19958,"status":"ok","timestamp":1712295811597,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"wsHsYTr-xmTb","outputId":"cc9a8077-0865-4608-ecba-4456e88fd0e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 completed\n","Epoch 1 completed\n","Epoch 2 completed\n","Epoch 3 completed\n","Epoch 4 completed\n","Time (weibo normal tgn): 19.26056408882141\n","Max memory usage (weibo normal tgn): 277239 KiB\n"]}],"source":["\n","import torch\n","from torch.nn import Module\n","from torch_geometric_temporal.nn.recurrent import GConvGRU\n","import time\n","setup_seed(42)\n","\n","gc.collect()\n","tracemalloc.start()\n","start_time = time.time()\n","\n","\n","\n","class CustomTemporalModel(Module):\n","    def __init__(self, node_features_dim, hidden_dim, total_nodes):\n","        super(CustomTemporalModel, self).__init__()\n","        self.gconv_gru = GConvGRU(node_features_dim, hidden_dim, 1)\n","        self.total_nodes = total_nodes\n","        self.node_embedding = torch.nn.Embedding(num_embeddings=total_nodes, embedding_dim=hidden_dim)\n","        # Initialize embeddings to zero\n","        self.node_embedding.weight.data = torch.zeros(total_nodes, hidden_dim)\n","\n","    def forward(self, snapshot_batches):\n","        presence_mask = torch.zeros(self.total_nodes, dtype=torch.bool)\n","\n","        for x_tensor, edge_index_tensor in snapshot_batches:\n","            node_indices = edge_index_tensor.unique()\n","            presence_mask[node_indices] = True  # Update presence mask\n","\n","            embedding = self.gconv_gru(x_tensor, edge_index_tensor, None)\n","            # Update embeddings for nodes in the current snapshot\n","            self.node_embedding.weight.data[node_indices] = embedding\n","\n","        # Use the presence_mask to calculate a weighted average or another sophisticated aggregation\n","        # Here, you need to decide how to aggregate taking presence_mask into account\n","        # For example, simply ignoring non-present nodes:\n","        aggregated_embeddings = self.node_embedding.weight.data[presence_mask]\n","\n","        return aggregated_embeddings\n","\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = CustomTemporalModel(node_features_dim, hidden_dim, total_nodes).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","num_epochs = 5\n","model.train()\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    snapshot_batches = []\n","    for snapshot in reindexed_snapshots:\n","        x = snapshot.x.to(device)\n","        edge_index = snapshot.edge_index.to(device)\n","        snapshot_batches.append((x, edge_index))\n","\n","    aggregated_embeddings = model(snapshot_batches)\n","\n","    optimizer.step()\n","\n","    print(f'Epoch {epoch} completed')\n","\n","print('Time (weibo normal tgn):',time.time() - start_time)\n","mem = tracemalloc.get_traced_memory()[-1]  # Calculate incremental memory usage\n","tracemalloc.stop()\n","print(f'Max memory usage (weibo normal tgn): {mem} KiB')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4676,"status":"ok","timestamp":1712295823337,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"RfiL59LzCsgS","outputId":"34b0dc30-9322-4de4-9577-828b72ef92ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","27/27 [==============================] - 1s 10ms/step - loss: 0.4129 - val_loss: 0.2886\n","Epoch 2/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.2602 - val_loss: 0.2355\n","Epoch 3/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.2285 - val_loss: 0.2162\n","Epoch 4/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.2127 - val_loss: 0.2037\n","Epoch 5/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.2013 - val_loss: 0.1944\n","Epoch 6/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.1926 - val_loss: 0.1874\n","Epoch 7/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1861 - val_loss: 0.1820\n","Epoch 8/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.1811 - val_loss: 0.1777\n","Epoch 9/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1771 - val_loss: 0.1743\n","Epoch 10/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1738 - val_loss: 0.1714\n","Epoch 11/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.1708 - val_loss: 0.1688\n","Epoch 12/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.1682 - val_loss: 0.1665\n","Epoch 13/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.1661 - val_loss: 0.1647\n","Epoch 14/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.1644 - val_loss: 0.1632\n","Epoch 15/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.1630 - val_loss: 0.1618\n","Epoch 16/25\n","27/27 [==============================] - 0s 5ms/step - loss: 0.1617 - val_loss: 0.1606\n","Epoch 17/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1606 - val_loss: 0.1596\n","Epoch 18/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1587\n","Epoch 19/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1588 - val_loss: 0.1579\n","Epoch 20/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1581 - val_loss: 0.1573\n","Epoch 21/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1574 - val_loss: 0.1566\n","Epoch 22/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1568 - val_loss: 0.1561\n","Epoch 23/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1563 - val_loss: 0.1556\n","Epoch 24/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1559 - val_loss: 0.1551\n","Epoch 25/25\n","27/27 [==============================] - 0s 4ms/step - loss: 0.1554 - val_loss: 0.1547\n","263/263 [==============================] - 0s 1ms/step\n","4.592441558837891\n"]}],"source":["final_embeddings_numpy = aggregated_embeddings.detach().numpy()\n","from keras.layers import Input, Dense\n","from keras.models import Model\n","setup_seed(42)\n","\n","start_time = time.time()\n","\n","# Define the size of our embeddings\n","input_dim = final_embeddings_numpy.shape[1]  # embedding_dimension\n","encoding_dim = 100 # or choose based on your dataset\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","\n","# Decoder\n","decoded = Dense(input_dim, activation='sigmoid')(encoded)\n","\n","# Autoencoder\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the model\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","setup_seed(42)\n","\n","\n","# Split the data\n","X_train, X_val = train_test_split(final_embeddings_numpy, test_size=0.2, random_state=42)\n","\n","\n","autoencoder.fit(X_train, X_train,\n","                epochs=25,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(X_val, X_val))\n","\n","# Reconstruct embeddings\n","setup_seed(42)\n","\n","reconstructed_embeddings = autoencoder.predict(final_embeddings_numpy)\n","\n","# Calculate mean squared error (MSE) as reconstruction error\n","reconstruction_error = np.mean(np.power(final_embeddings_numpy - reconstructed_embeddings, 2), axis=1)\n","\n","threshold = np.mean(reconstruction_error) + np.std(reconstruction_error)\n","# Flag embeddings with errors above the threshold as anomalies\n","anomalies = reconstruction_error > threshold\n","\n","print(time.time() - start_time)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"idnQgTAOZBMP"},"outputs":[],"source":["predicted_list = [int(value) for value in anomalies]\n","true_labels = [0 if x == 0 else 1 for x in list(dataset.y)]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":117,"status":"ok","timestamp":1712295825003,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"Dx9T3oCJW5lp","outputId":"d4acd73c-3a53-4967-ef4c-94013f13f0db"},"outputs":[{"name":"stdout","output_type":"stream","text":["ROC Score: 0.7878679286984921\n"]}],"source":["from pygod.metric import eval_roc_auc, eval_f1\n","# f1_score = eval_f1(dataset.y, predicted_list)\n","# print('F1 Score:', f1_score)\n","roc_score = eval_roc_auc(dataset.y, reconstruction_error)\n","print('ROC Score:', roc_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xc5fJzT1Yqqv"},"outputs":[],"source":["weibo['pred']['normalTGN']=predicted_list\n","weibo['prob']['normalTGN']=reconstruction_error"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShKvOHWxCJoL"},"outputs":[],"source":["import pickle\n","import torch\n","\n","\n","with open(\"tgn_node_embeddings/NormalTGN_weibo_node_embeddings.pkl\", \"wb\") as f:\n","    pickle.dump(final_embeddings_numpy, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Eu9F7A_9JZj"},"outputs":[],"source":["import pickle\n","import torch\n","with open(\"tgn_node_embeddings/NormalTGN_weibo_node_embeddings.pkl\", \"rb\") as f:\n","    final_embeddings_numpy = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lvaVQEFL3npY"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"nAZNyyN48yWJ"},"source":["### TGN with enhanced embedding aggregation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43821,"status":"ok","timestamp":1712366504058,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"YFlW7rgcCRxE","outputId":"e3ec2de0-cd88-46f3-d47a-fab6ba1ab16e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 completed\n","Epoch 1 completed\n","Epoch 2 completed\n","Epoch 3 completed\n","Time (weibo tgn lstm): 42.72486114501953\n","Max memory usage (weibo lstm tgn): 523129 KiB\n"]}],"source":["setup_seed(42)\n","\n","gc.collect()\n","tracemalloc.start()\n","\n","start_time = time.time()\n","\n","class CustomTemporalModel(Module):\n","    def __init__(self, node_features_dim, hidden_dim, total_nodes, device,num_gconv_gru_layers=2, num_lstm_layers=2):\n","        super(CustomTemporalModel, self).__init__()\n","        self.device = device\n","        # self.gconv_gru = GConvGRU(node_features_dim, hidden_dim, 1).to(device)\n","        # self.lstm = LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True).to(device)\n","                # Stack multiple GConvGRU layers\n","\n","        self.num_gconv_gru_layers = num_gconv_gru_layers\n","        # self.num_lstm_layers = num_lstm_layers\n","\n","        self.gconv_gru = ModuleList([\n","            GConvGRU(node_features_dim if i == 0 else hidden_dim, hidden_dim, 1).to(device)\n","            for i in range(num_gconv_gru_layers)\n","        ])\n","\n","        # Use an LSTM with multiple layers\n","        self.lstm = LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True, num_layers=num_lstm_layers).to(device)\n","\n","        self.total_nodes = total_nodes\n","        self.hidden_dim = hidden_dim\n","        # Each node's embeddings across snapshots will be stored here\n","        self.node_embeddings_history = torch.zeros(total_nodes, 0, hidden_dim).to(device)\n","        self.node_embedding = torch.nn.Embedding(num_embeddings=total_nodes, embedding_dim=hidden_dim).to(device)\n","        # Initialize embeddings to zero\n","        self.node_embedding.weight.data = torch.zeros(total_nodes, hidden_dim).to(device)\n","\n","    def forward(self, snapshot_batches):\n","        presence_mask = torch.zeros(self.total_nodes, dtype=torch.bool).to(self.device)\n","\n","        # Temporary storage for the current snapshot's embeddings\n","        current_snapshot_embeddings = torch.zeros(self.total_nodes, self.hidden_dim).to(self.device)\n","\n","        for x_tensor, edge_index_tensor in snapshot_batches:\n","            node_indices = edge_index_tensor.unique()\n","            presence_mask[node_indices] = True  # Update presence mask\n","            embedding = x_tensor\n","            for gconv_gru in self.gconv_gru:\n","                embedding = gconv_gru(embedding, edge_index_tensor, None)\n","\n","            # embedding = self.gconv_gru(x_tensor, edge_index_tensor, None)\n","            current_snapshot_embeddings[node_indices] = embedding\n","\n","        # Update the history of embeddings with the current snapshot's embeddings\n","        # Add an extra dimension for \"sequence length\" to match LSTM input\n","        current_snapshot_embeddings = current_snapshot_embeddings.unsqueeze(1)\n","        self.node_embeddings_history = torch.cat((self.node_embeddings_history, current_snapshot_embeddings), dim=1)\n","\n","        # Use LSTM to process the temporal sequence of embeddings for each node\n","        lstm_out, (hn, cn) = self.lstm(self.node_embeddings_history)\n","\n","        aggregated_embeddings = hn[-1]\n","\n","\n","        # The last hidden state `hn` represents the aggregated embedding considering the temporal dimension\n","        aggregated_embeddings = hn.squeeze(0)  # Remove the first dimension for batch\n","\n","        if aggregated_embeddings.dim() == 3:  # When it's (batch, nodes, features)\n","    # Selecting the embeddings of present nodes across all batches\n","            aggregated_embeddings = aggregated_embeddings[:, presence_mask, :]\n","        elif aggregated_embeddings.dim() == 2:  # When it's (nodes, features)\n","            aggregated_embeddings = aggregated_embeddings[presence_mask]\n","\n","\n","        return aggregated_embeddings\n","\n","\n","\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cpu\")\n","\n","model = CustomTemporalModel(node_features_dim, hidden_dim, total_nodes, device).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\n","\n","num_epochs = 4\n","model.train()\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    snapshot_batches = []\n","    for snapshot in reindexed_snapshots:\n","        x = snapshot.x.to(device)\n","        edge_index = snapshot.edge_index.to(device)\n","        snapshot_batches.append((x, edge_index))\n","\n","    aggregated_embeddings = model(snapshot_batches)[-1]\n","\n","    optimizer.step()\n","\n","    print(f'Epoch {epoch} completed')\n","\n","print('Time (weibo tgn lstm):',time.time() - start_time)\n","mem = tracemalloc.get_traced_memory()[-1]\n","tracemalloc.stop()\n","print(f'Max memory usage (weibo lstm tgn): {mem} KiB')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TtgKx0MfEc6g"},"outputs":[],"source":["final_embeddings_numpy = aggregated_embeddings.detach().cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-KY5xriVfnc"},"outputs":[],"source":["import pickle\n","import torch\n","with open(\"tgn_node_embeddings/LSTM_TGN_weibo_node_embeddings.pkl\", \"rb\") as f:\n","    final_embeddings_numpy = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12075,"status":"ok","timestamp":1712366522861,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"eie1w3LFCjaY","outputId":"da1d0ebe-d541-41c9-85b9-cf75673ce0e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","27/27 [==============================] - 1s 13ms/step - loss: 0.2236 - val_loss: 0.1704\n","Epoch 2/25\n","27/27 [==============================] - 0s 8ms/step - loss: 0.0991 - val_loss: 0.0336\n","Epoch 3/25\n","27/27 [==============================] - 0s 9ms/step - loss: 0.0153 - val_loss: 0.0058\n","Epoch 4/25\n","27/27 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0028\n","Epoch 5/25\n","27/27 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0019\n","Epoch 6/25\n","27/27 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0015\n","Epoch 7/25\n","27/27 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0013\n","Epoch 8/25\n","27/27 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n","Epoch 9/25\n","27/27 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n","Epoch 10/25\n","27/27 [==============================] - 0s 8ms/step - loss: 9.6750e-04 - val_loss: 9.2813e-04\n","Epoch 11/25\n","27/27 [==============================] - 0s 8ms/step - loss: 9.0375e-04 - val_loss: 8.7351e-04\n","Epoch 12/25\n","27/27 [==============================] - 0s 7ms/step - loss: 8.5551e-04 - val_loss: 8.3170e-04\n","Epoch 13/25\n","27/27 [==============================] - 0s 7ms/step - loss: 8.1810e-04 - val_loss: 7.9881e-04\n","Epoch 14/25\n","27/27 [==============================] - 0s 7ms/step - loss: 7.8837e-04 - val_loss: 7.7236e-04\n","Epoch 15/25\n","27/27 [==============================] - 0s 7ms/step - loss: 7.6429e-04 - val_loss: 7.5071e-04\n","Epoch 16/25\n","27/27 [==============================] - 0s 8ms/step - loss: 7.4448e-04 - val_loss: 7.3278e-04\n","Epoch 17/25\n","27/27 [==============================] - 0s 7ms/step - loss: 7.2794e-04 - val_loss: 7.1774e-04\n","Epoch 18/25\n","27/27 [==============================] - 0s 7ms/step - loss: 7.1400e-04 - val_loss: 7.0497e-04\n","Epoch 19/25\n","27/27 [==============================] - 0s 8ms/step - loss: 7.0212e-04 - val_loss: 6.9402e-04\n","Epoch 20/25\n","27/27 [==============================] - 0s 8ms/step - loss: 6.9192e-04 - val_loss: 6.8460e-04\n","Epoch 21/25\n","27/27 [==============================] - 0s 8ms/step - loss: 6.8308e-04 - val_loss: 6.7641e-04\n","Epoch 22/25\n","27/27 [==============================] - 0s 7ms/step - loss: 6.7538e-04 - val_loss: 6.6924e-04\n","Epoch 23/25\n","27/27 [==============================] - 0s 7ms/step - loss: 6.6863e-04 - val_loss: 6.6294e-04\n","Epoch 24/25\n","27/27 [==============================] - 0s 7ms/step - loss: 6.6268e-04 - val_loss: 6.5737e-04\n","Epoch 25/25\n","27/27 [==============================] - 0s 8ms/step - loss: 6.5741e-04 - val_loss: 6.5243e-04\n","263/263 [==============================] - 1s 3ms/step\n","12.065800428390503\n"]}],"source":["from keras.layers import Input, Dense\n","from keras.models import Model\n","setup_seed(42)\n","\n","start_time = time.time()\n","\n","\n","# Define the size of our embeddings\n","input_dim = final_embeddings_numpy.shape[1]  # embedding_dimension\n","encoding_dim = 100 # or choose based on your dataset\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","\n","# Decoder\n","decoded = Dense(input_dim, activation='sigmoid')(encoded)\n","\n","# Autoencoder\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the model\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","setup_seed(42)\n","\n","\n","# Split the data\n","X_train, X_val = train_test_split(final_embeddings_numpy, test_size=0.2, random_state=42)\n","\n","\n","autoencoder.fit(X_train, X_train,\n","                epochs=25,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(X_val, X_val))\n","\n","# Reconstruct embeddings\n","setup_seed(42)\n","\n","reconstructed_embeddings = autoencoder.predict(final_embeddings_numpy)\n","\n","# Calculate mean squared error (MSE) as reconstruction error\n","reconstruction_error = np.mean(np.power(final_embeddings_numpy - reconstructed_embeddings, 2), axis=1)\n","\n","threshold = np.mean(reconstruction_error) + np.std(reconstruction_error)\n","# Flag embeddings with errors above the threshold as anomalies\n","anomalies = reconstruction_error > threshold\n","\n","print(time.time() - start_time)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UxoGQpUSZkVY"},"outputs":[],"source":["predicted_list = [int(value) for value in anomalies]\n","true_labels = [0 if x == 0 else 1 for x in list(dataset.y)]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":210,"status":"ok","timestamp":1712288772828,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"EU1U9-RqWc2T","outputId":"70373c77-718f-4499-c2e0-ec37ef59e98b"},"outputs":[{"name":"stdout","output_type":"stream","text":["ROC Score: 0.856675271429113\n"]}],"source":["from pygod.metric import eval_roc_auc, eval_f1\n","# f1_score = eval_f1(dataset.y, predicted_list)\n","# print('F1 Score:', f1_score)\n","roc_score = eval_roc_auc(dataset.y, reconstruction_error)\n","print('ROC Score:', roc_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YDgeyj7aZiXD"},"outputs":[],"source":["weibo['pred']['lstmTGN']=predicted_list\n","weibo['prob']['lstmTGN']=reconstruction_error"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxw0BF_4EjNi"},"outputs":[],"source":["import pickle\n","import torch\n","\n","\n","with open(\"tgn_node_embeddings/LSTM_TGN_weibo_node_embeddings.pkl\", \"wb\") as f:\n","    pickle.dump(final_embeddings_numpy, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NGANtrfFMrJ"},"outputs":[],"source":["with open('data/weibo_bond_results.pkl', 'wb') as file:\n","    pickle.dump(weibo, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":187,"status":"ok","timestamp":1712289043573,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"kg-jGF7WX6Az","outputId":"d0712126-dff9-4316-a0a6-ead3cdbad669"},"outputs":[{"data":{"text/plain":["8405"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["len(weibo['pred['y_true'])"]},{"cell_type":"markdown","metadata":{"id":"PxCgXAsH5nj0"},"source":["# Reddit Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dApZh4745rDN"},"outputs":[],"source":["from pygod.utils import load_data\n","data = load_data('reddit')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7524103,"status":"ok","timestamp":1712121396024,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"7xQHerPy8EU1","outputId":"81d638cb-7353-4eae-9ac2-1262d4eff6b6"},"outputs":[],"source":["roc_scores, pred, prob, timing, memory_consumption = bond_pipeline(data)\n","\n","import pickle\n","filename = 'data/reddit_bond_results.pkl'\n","\n","# Open the file in binary write mode and save (pickle) the dictionary\n","my_dict = {'roc_scores': roc_scores, 'pred': pred, 'prob': prob, 'timing': timing, 'memory_consumption': memory_consumption}\n","with open(filename, 'wb') as file:\n","    pickle.dump(my_dict, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pmOk3kxphN-"},"outputs":[],"source":["lstm_tgn_prob = my_dict['prob']['DONE']\n","lstm_tgn_roc = my_dict['roc_scores']['DONE']\n","lstm_tgn_pred = my_dict['pred']['DONE']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WyAbhDslWK8y"},"outputs":[],"source":["with open('data/reddit_bond_results.pkl', 'rb') as file:\n","    loaded_dict = pickle.load(file)\n","\n","loaded_dict['y_true']=data.y\n","\n","with open('data/reddit_bond_results.pkl', 'wb') as file:\n","    pickle.dump(loaded_dict, file)"]},{"cell_type":"markdown","metadata":{"id":"BnAZCT_DSnOJ"},"source":["## TGN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBgeNJ0J55A7"},"outputs":[],"source":["setup_seed(42)\n","start_date = datetime.now()\n","end_date = start_date + timedelta(days=30)\n","total_days = (end_date - start_date).days\n","\n","# Generate random timestamps within the window\n","timestamps = np.random.randint(0, total_days, size=(data.edge_index.size(1),))\n","\n","def create_incremental_snapshots(data, timestamps, total_days):\n","    snapshots = []\n","    accumulated_edges = torch.empty((2, 0), dtype=torch.long)\n","    accumulated_nodes = torch.tensor([], dtype=torch.long)\n","\n","    for day in range(total_days):\n","        # Select edges that fall into the current day\n","        mask = timestamps == day  # Change to == to only get new edges for the day\n","        new_edges_day = data.edge_index[:, mask]\n","\n","        if new_edges_day.size(1) > 0:  # If there are new edges for this day\n","            accumulated_edges = torch.cat([accumulated_edges, new_edges_day], dim=1)  # Accumulate new edges\n","            new_nodes = torch.unique(new_edges_day)\n","            accumulated_nodes = torch.unique(torch.cat([accumulated_nodes, new_nodes]))  # Accumulate nodes connected by new edges\n","\n","        if accumulated_edges.size(1) > 0:  # If there are accumulated edges\n","            sub_data = Data(edge_index=accumulated_edges, num_nodes=data.num_nodes)\n","            if data.x is not None:\n","                sub_data.x = data.x[accumulated_nodes]\n","            snapshots.append(sub_data)\n","        else:\n","            # If no edges have been accumulated yet, create a placeholder or handle accordingly\n","            pass\n","\n","    return snapshots\n","\n","# Create the incremental daily snapshots\n","snapshots = create_incremental_snapshots(data, timestamps, total_days)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":117,"status":"ok","timestamp":1712189320684,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"hIFKsSa_EBYD","outputId":"25fee35a-ac3e-452f-8dce-0933c26366d2"},"outputs":[{"data":{"text/plain":["[Data(edge_index=[2, 5558], num_nodes=10984, x=[4335, 64]),\n"," Data(edge_index=[2, 11151], num_nodes=10984, x=[6205, 64]),\n"," Data(edge_index=[2, 16607], num_nodes=10984, x=[7300, 64]),\n"," Data(edge_index=[2, 22232], num_nodes=10984, x=[8019, 64]),\n"," Data(edge_index=[2, 27879], num_nodes=10984, x=[8557, 64]),\n"," Data(edge_index=[2, 33435], num_nodes=10984, x=[8975, 64]),\n"," Data(edge_index=[2, 38993], num_nodes=10984, x=[9308, 64]),\n"," Data(edge_index=[2, 44560], num_nodes=10984, x=[9569, 64]),\n"," Data(edge_index=[2, 50160], num_nodes=10984, x=[9802, 64]),\n"," Data(edge_index=[2, 55783], num_nodes=10984, x=[10002, 64]),\n"," Data(edge_index=[2, 61272], num_nodes=10984, x=[10160, 64]),\n"," Data(edge_index=[2, 66901], num_nodes=10984, x=[10295, 64]),\n"," Data(edge_index=[2, 72630], num_nodes=10984, x=[10446, 64]),\n"," Data(edge_index=[2, 78082], num_nodes=10984, x=[10542, 64]),\n"," Data(edge_index=[2, 83679], num_nodes=10984, x=[10612, 64]),\n"," Data(edge_index=[2, 89369], num_nodes=10984, x=[10692, 64]),\n"," Data(edge_index=[2, 94946], num_nodes=10984, x=[10759, 64]),\n"," Data(edge_index=[2, 100448], num_nodes=10984, x=[10802, 64]),\n"," Data(edge_index=[2, 106040], num_nodes=10984, x=[10840, 64]),\n"," Data(edge_index=[2, 111611], num_nodes=10984, x=[10879, 64]),\n"," Data(edge_index=[2, 117178], num_nodes=10984, x=[10902, 64]),\n"," Data(edge_index=[2, 122843], num_nodes=10984, x=[10931, 64]),\n"," Data(edge_index=[2, 128592], num_nodes=10984, x=[10952, 64]),\n"," Data(edge_index=[2, 134158], num_nodes=10984, x=[10963, 64]),\n"," Data(edge_index=[2, 139746], num_nodes=10984, x=[10973, 64]),\n"," Data(edge_index=[2, 145481], num_nodes=10984, x=[10978, 64]),\n"," Data(edge_index=[2, 151030], num_nodes=10984, x=[10982, 64]),\n"," Data(edge_index=[2, 156610], num_nodes=10984, x=[10984, 64]),\n"," Data(edge_index=[2, 162301], num_nodes=10984, x=[10984, 64]),\n"," Data(edge_index=[2, 168016], num_nodes=10984, x=[10984, 64])]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["snapshots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOx0TTL4KoeQ"},"outputs":[],"source":["import torch\n","from torch_geometric.data import Data\n","import torch\n","\n","def reindex_nodes(data_snapshot):\n","    \"\"\"\n","    Adjusts edge_index and x to ensure node indices are continuous and synchronized.\n","    :param data_snapshot: A Data object containing x (node features) and edge_index.\n","    :return: A new Data object with adjusted edge_index and potentially x.\n","    \"\"\"\n","    unique_nodes, new_indices = torch.unique(data_snapshot.edge_index, return_inverse=True)\n","    num_nodes = data_snapshot.x.size(0)\n","\n","    # Initialize a new x if necessary\n","    if len(unique_nodes) != num_nodes:\n","        new_x = torch.zeros((len(unique_nodes), data_snapshot.x.size(1)), dtype=data_snapshot.x.dtype)\n","        new_x[unique_nodes] = data_snapshot.x[:len(unique_nodes)]\n","    else:\n","        new_x = data_snapshot.x\n","\n","    # Reshape new_indices to match the shape of edge_index\n","    new_edge_index = new_indices.view(data_snapshot.edge_index.size())\n","\n","    return Data(x=new_x, edge_index=new_edge_index, y=data_snapshot.y if hasattr(data_snapshot, 'y') else None)\n","\n","\n","reindexed_snapshots = [reindex_nodes(snapshot) for snapshot in snapshots]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rckGXSB5K0KB"},"outputs":[],"source":["num_snapshots = 0\n","for snap in reindexed_snapshots:\n","  num_snapshots+=1\n","\n","\n","node_features_dim = 64\n","hidden_dim = 200\n","\n","num_epochs = 5\n","learning_rate = 0.01\n","total_nodes = 10984  # Make sure this is the maximum number of nodes in any snapshot\n"]},{"cell_type":"markdown","metadata":{"id":"gIYYdmUYHju1"},"source":["### TGN with normal aggregation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13571,"status":"ok","timestamp":1712193345919,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"96UuMPXfHnKQ","outputId":"c3911b37-c2c7-47f9-9e62-4108c27406fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 completed\n","Epoch 1 completed\n","Epoch 2 completed\n","Epoch 3 completed\n","Epoch 4 completed\n","Time (reddit normal tgn): 12.744897365570068\n","Max memory usage (reddit normal tgn): 254112 KiB\n"]}],"source":["\n","import torch\n","from torch.nn import Module\n","from torch_geometric_temporal.nn.recurrent import GConvGRU\n","setup_seed(42)\n","\n","gc.collect()\n","tracemalloc.start()\n","start_time = time.time()\n","\n","\n","        # Measure ending memory usage\n","\n","\n","class CustomTemporalModel(Module):\n","    def __init__(self, node_features_dim, hidden_dim, total_nodes):\n","        super(CustomTemporalModel, self).__init__()\n","        self.gconv_gru = GConvGRU(node_features_dim, hidden_dim, 1)\n","        self.total_nodes = total_nodes\n","        self.node_embedding = torch.nn.Embedding(num_embeddings=total_nodes, embedding_dim=hidden_dim)\n","        # Initialize embeddings to zero\n","        self.node_embedding.weight.data = torch.zeros(total_nodes, hidden_dim)\n","\n","    def forward(self, snapshot_batches):\n","        presence_mask = torch.zeros(self.total_nodes, dtype=torch.bool)\n","\n","        for x_tensor, edge_index_tensor in snapshot_batches:\n","            node_indices = edge_index_tensor.unique()\n","            presence_mask[node_indices] = True  # Update presence mask\n","\n","            embedding = self.gconv_gru(x_tensor, edge_index_tensor, None)\n","            self.node_embedding.weight.data[node_indices] = embedding\n","\n","\n","        aggregated_embeddings = self.node_embedding.weight.data[presence_mask]\n","\n","        return aggregated_embeddings\n","\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cpu\")\n","\n","model = CustomTemporalModel(node_features_dim, hidden_dim, total_nodes).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","num_epochs = 5\n","model.train()\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    snapshot_batches = []\n","    for snapshot in reindexed_snapshots:\n","        x = snapshot.x.to(device)\n","        edge_index = snapshot.edge_index.to(device)\n","        snapshot_batches.append((x, edge_index))\n","\n","    aggregated_embeddings = model(snapshot_batches)\n","\n","    optimizer.step()\n","\n","    print(f'Epoch {epoch} completed')\n","\n","print('Time (reddit normal tgn):',time.time() - start_time)\n","mem = tracemalloc.get_traced_memory()[-1]  # Calculate incremental memory usage\n","tracemalloc.stop()\n","print(f'Max memory usage (reddit normal tgn): {mem} KiB')\n","\n","\n","final_embeddings_numpy = aggregated_embeddings.cpu().detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6560,"status":"ok","timestamp":1712193383488,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"ATV1wd3gI7ej","outputId":"fb4f8cdc-7ad9-42fe-b4d0-27170b8d1073"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","35/35 [==============================] - 1s 11ms/step - loss: 0.2385 - val_loss: 0.2147\n","Epoch 2/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.1724 - val_loss: 0.1191\n","Epoch 3/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0769 - val_loss: 0.0414\n","Epoch 4/25\n","35/35 [==============================] - 0s 6ms/step - loss: 0.0263 - val_loss: 0.0155\n","Epoch 5/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0078\n","Epoch 6/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0048\n","Epoch 7/25\n","35/35 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0033\n","Epoch 8/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0024\n","Epoch 9/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0018\n","Epoch 10/25\n","35/35 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0015\n","Epoch 11/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n","Epoch 12/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n","Epoch 13/25\n","35/35 [==============================] - 0s 5ms/step - loss: 9.3248e-04 - val_loss: 8.5618e-04\n","Epoch 14/25\n","35/35 [==============================] - 0s 6ms/step - loss: 7.9865e-04 - val_loss: 7.3875e-04\n","Epoch 15/25\n","35/35 [==============================] - 0s 5ms/step - loss: 6.9310e-04 - val_loss: 6.4513e-04\n","Epoch 16/25\n","35/35 [==============================] - 0s 5ms/step - loss: 6.0825e-04 - val_loss: 5.6919e-04\n","Epoch 17/25\n","35/35 [==============================] - 0s 5ms/step - loss: 5.3893e-04 - val_loss: 5.0666e-04\n","Epoch 18/25\n","35/35 [==============================] - 0s 5ms/step - loss: 4.8151e-04 - val_loss: 4.5451e-04\n","Epoch 19/25\n","35/35 [==============================] - 0s 5ms/step - loss: 4.3336e-04 - val_loss: 4.1051e-04\n","Epoch 20/25\n","35/35 [==============================] - 0s 5ms/step - loss: 3.9255e-04 - val_loss: 3.7304e-04\n","Epoch 21/25\n","35/35 [==============================] - 0s 5ms/step - loss: 3.5764e-04 - val_loss: 3.4082e-04\n","Epoch 22/25\n","35/35 [==============================] - 0s 5ms/step - loss: 3.2752e-04 - val_loss: 3.1293e-04\n","Epoch 23/25\n","35/35 [==============================] - 0s 5ms/step - loss: 3.0135e-04 - val_loss: 2.8858e-04\n","Epoch 24/25\n","35/35 [==============================] - 0s 5ms/step - loss: 2.7843e-04 - val_loss: 2.6721e-04\n","Epoch 25/25\n","35/35 [==============================] - 0s 5ms/step - loss: 2.5826e-04 - val_loss: 2.4832e-04\n","344/344 [==============================] - 1s 1ms/step\n","6.625180721282959\n"]}],"source":["from keras.layers import Input, Dense\n","from keras.models import Model\n","setup_seed(42)\n","\n","start_time = time.time()\n","\n","\n","# Define the size of our embeddings\n","input_dim = final_embeddings_numpy.shape[1]  # embedding_dimension\n","encoding_dim = 100 # or choose based on your dataset\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","\n","# Decoder\n","decoded = Dense(input_dim, activation='sigmoid')(encoded)\n","\n","# Autoencoder\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the model\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","setup_seed(42)\n","\n","\n","# Split the data\n","X_train, X_val = train_test_split(final_embeddings_numpy, test_size=0.2, random_state=42)\n","\n","\n","autoencoder.fit(X_train, X_train,\n","                epochs=25,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(X_val, X_val))\n","\n","# Reconstruct embeddings\n","setup_seed(42)\n","\n","reconstructed_embeddings = autoencoder.predict(final_embeddings_numpy)\n","\n","# Calculate mean squared error (MSE) as reconstruction error\n","reconstruction_error = np.mean(np.power(final_embeddings_numpy - reconstructed_embeddings, 2), axis=1)\n","\n","threshold = np.mean(reconstruction_error) + np.std(reconstruction_error)\n","# Flag embeddings with errors above the threshold as anomalies\n","anomalies = reconstruction_error > threshold\n","\n","print(time.time() - start_time)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132,"status":"ok","timestamp":1712193385465,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"lwdLLYHRJkKs","outputId":"1a7f8107-5456-47f2-f541-bcd52d49da60"},"outputs":[{"data":{"text/plain":["0.00025654718"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["threshold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BVv1D-Ld5XJ"},"outputs":[],"source":["\n","loaded_dict['pred']['normalTGN'] = anomalies\n","loaded_dict['prob']['normalTGN'] = reconstruction_error\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pEDBmc46LKI6"},"source":["### TGN with LSTM aggregation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35678,"status":"ok","timestamp":1712190090627,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"chaLuEsc942z","outputId":"956dfc5f-fc4a-43f6-cd5e-c4ccdadf39c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 completed\n","Epoch 1 completed\n","Epoch 2 completed\n","Epoch 3 completed\n","Epoch 4 completed\n","Time (reddit tgn lstm): 33.952409982681274\n","Max memory usage (reddit tgn lstm): 519371 KiB\n"]}],"source":["\n","import torch\n","from torch.nn import Module, LSTM\n","from torch_geometric_temporal.nn.recurrent import GConvGRU\n","setup_seed(42)\n","\n","gc.collect()\n","tracemalloc.start()\n","start_time = time.time()\n","\n","start_mem = memory_usage(-1, interval=0.1, timeout=1)\n","\n","\n","\n","\n","class CustomTemporalModel(Module):\n","    def __init__(self, node_features_dim, hidden_dim, total_nodes, device,num_gconv_gru_layers=2, num_lstm_layers=2):\n","        super(CustomTemporalModel, self).__init__()\n","        self.device = device\n","        # self.gconv_gru = GConvGRU(node_features_dim, hidden_dim, 1).to(device)\n","        # self.lstm = LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True).to(device)\n","                # Stack multiple GConvGRU layers\n","\n","        self.num_gconv_gru_layers = num_gconv_gru_layers\n","        # self.num_lstm_layers = num_lstm_layers\n","\n","        self.gconv_gru = ModuleList([\n","            GConvGRU(node_features_dim if i == 0 else hidden_dim, hidden_dim, 1).to(device)\n","            for i in range(num_gconv_gru_layers)\n","        ])\n","\n","        # Use an LSTM with multiple layers\n","        self.lstm = LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True, num_layers=num_lstm_layers).to(device)\n","\n","        self.total_nodes = total_nodes\n","        self.hidden_dim = hidden_dim\n","        # Each node's embeddings across snapshots will be stored here\n","        self.node_embeddings_history = torch.zeros(total_nodes, 0, hidden_dim).to(device)\n","        self.node_embedding = torch.nn.Embedding(num_embeddings=total_nodes, embedding_dim=hidden_dim).to(device)\n","        # Initialize embeddings to zero\n","        self.node_embedding.weight.data = torch.zeros(total_nodes, hidden_dim).to(device)\n","\n","    def forward(self, snapshot_batches):\n","        presence_mask = torch.zeros(self.total_nodes, dtype=torch.bool).to(self.device)\n","\n","        # Temporary storage for the current snapshot's embeddings\n","        current_snapshot_embeddings = torch.zeros(self.total_nodes, self.hidden_dim).to(self.device)\n","\n","        for x_tensor, edge_index_tensor in snapshot_batches:\n","            node_indices = edge_index_tensor.unique()\n","            presence_mask[node_indices] = True  # Update presence mask\n","            embedding = x_tensor\n","            for gconv_gru in self.gconv_gru:\n","                embedding = gconv_gru(embedding, edge_index_tensor, None)\n","\n","            # embedding = self.gconv_gru(x_tensor, edge_index_tensor, None)\n","            current_snapshot_embeddings[node_indices] = embedding\n","\n","        # Update the history of embeddings with the current snapshot's embeddings\n","        # Add an extra dimension for \"sequence length\" to match LSTM input\n","        current_snapshot_embeddings = current_snapshot_embeddings.unsqueeze(1)\n","        self.node_embeddings_history = torch.cat((self.node_embeddings_history, current_snapshot_embeddings), dim=1)\n","\n","        # Use LSTM to process the temporal sequence of embeddings for each node\n","        lstm_out, (hn, cn) = self.lstm(self.node_embeddings_history)\n","\n","        aggregated_embeddings = hn[-1]\n","\n","\n","        # The last hidden state `hn` represents the aggregated embedding considering the temporal dimension\n","        aggregated_embeddings = hn.squeeze(0)  # Remove the first dimension for batch\n","\n","        if aggregated_embeddings.dim() == 3:  # When it's (batch, nodes, features)\n","    # Selecting the embeddings of present nodes across all batches\n","            aggregated_embeddings = aggregated_embeddings[:, presence_mask, :]\n","        elif aggregated_embeddings.dim() == 2:  # When it's (nodes, features)\n","            aggregated_embeddings = aggregated_embeddings[presence_mask]\n","\n","\n","        return aggregated_embeddings\n","\n","\n","\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cpu\")\n","\n","model = CustomTemporalModel(node_features_dim, hidden_dim, total_nodes, device).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","start_time = time.time()\n","\n","start_mem = memory_usage(-1, interval=0.1, timeout=1)\n","\n","\n","num_epochs = 5\n","model.train()\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    snapshot_batches = []\n","    for snapshot in reindexed_snapshots:\n","        x = snapshot.x.to(device)\n","        edge_index = snapshot.edge_index.to(device)\n","        snapshot_batches.append((x, edge_index))\n","\n","    aggregated_embeddings = model(snapshot_batches)\n","\n","    optimizer.step()\n","\n","    print(f'Epoch {epoch} completed')\n","\n","print('Time (reddit tgn lstm):',time.time() - start_time)\n","\n","\n","mem = tracemalloc.get_traced_memory()[-1]  # Calculate incremental memory usage\n","tracemalloc.stop()\n","print(f'Max memory usage (reddit tgn lstm): {mem} KiB')\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2KkuW7uU8WVu"},"outputs":[],"source":["final_embeddings_numpy = aggregated_embeddings.cpu().detach().numpy()[-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6406,"status":"ok","timestamp":1712190104034,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"SdiXiZuA2BrH","outputId":"31b8d273-42dd-4653-f148-62b8665fa149"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","35/35 [==============================] - 1s 10ms/step - loss: 0.2173 - val_loss: 0.1493\n","Epoch 2/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0771 - val_loss: 0.0242\n","Epoch 3/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0062\n","Epoch 4/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0033\n","Epoch 5/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0023\n","Epoch 6/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0018\n","Epoch 7/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n","Epoch 8/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n","Epoch 9/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n","Epoch 10/25\n","35/35 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n","Epoch 11/25\n","35/35 [==============================] - 0s 5ms/step - loss: 9.8750e-04 - val_loss: 9.4729e-04\n","Epoch 12/25\n","35/35 [==============================] - 0s 5ms/step - loss: 9.1611e-04 - val_loss: 8.8436e-04\n","Epoch 13/25\n","35/35 [==============================] - 0s 5ms/step - loss: 8.5936e-04 - val_loss: 8.3372e-04\n","Epoch 14/25\n","35/35 [==============================] - 0s 5ms/step - loss: 8.1327e-04 - val_loss: 7.9219e-04\n","Epoch 15/25\n","35/35 [==============================] - 0s 5ms/step - loss: 7.7519e-04 - val_loss: 7.5757e-04\n","Epoch 16/25\n","35/35 [==============================] - 0s 5ms/step - loss: 7.4325e-04 - val_loss: 7.2834e-04\n","Epoch 17/25\n","35/35 [==============================] - 0s 5ms/step - loss: 7.1612e-04 - val_loss: 7.0336e-04\n","Epoch 18/25\n","35/35 [==============================] - 0s 5ms/step - loss: 6.9284e-04 - val_loss: 6.8182e-04\n","Epoch 19/25\n","35/35 [==============================] - 0s 5ms/step - loss: 6.7268e-04 - val_loss: 6.6307e-04\n","Epoch 20/25\n","35/35 [==============================] - 0s 5ms/step - loss: 6.5507e-04 - val_loss: 6.4664e-04\n","Epoch 21/25\n","35/35 [==============================] - 0s 4ms/step - loss: 6.3959e-04 - val_loss: 6.3215e-04\n","Epoch 22/25\n","35/35 [==============================] - 0s 5ms/step - loss: 6.2589e-04 - val_loss: 6.1927e-04\n","Epoch 23/25\n","35/35 [==============================] - 0s 5ms/step - loss: 6.1369e-04 - val_loss: 6.0778e-04\n","Epoch 24/25\n","35/35 [==============================] - 0s 5ms/step - loss: 6.0277e-04 - val_loss: 5.9747e-04\n","Epoch 25/25\n","35/35 [==============================] - 0s 5ms/step - loss: 5.9296e-04 - val_loss: 5.8817e-04\n","344/344 [==============================] - 1s 2ms/step\n","6.1522910594940186\n"]}],"source":["from keras.layers import Input, Dense\n","from keras.models import Model\n","setup_seed(42)\n","\n","start_time = time.time()\n","\n","\n","# Define the size of our embeddings\n","input_dim = final_embeddings_numpy.shape[1]  # embedding_dimension\n","encoding_dim = 100 # or choose based on your dataset\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","\n","# Decoder\n","decoded = Dense(input_dim, activation='sigmoid')(encoded)\n","\n","# Autoencoder\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the model\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","setup_seed(42)\n","\n","\n","# Split the data\n","X_train, X_val = train_test_split(final_embeddings_numpy, test_size=0.2, random_state=42)\n","\n","\n","autoencoder.fit(X_train, X_train,\n","                epochs=25,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(X_val, X_val))\n","\n","# Reconstruct embeddings\n","setup_seed(42)\n","\n","reconstructed_embeddings = autoencoder.predict(final_embeddings_numpy)\n","\n","# Calculate mean squared error (MSE) as reconstruction error\n","reconstruction_error = np.mean(np.power(final_embeddings_numpy - reconstructed_embeddings, 2), axis=1)\n","\n","threshold = np.mean(reconstruction_error) + np.std(reconstruction_error)\n","# Flag embeddings with errors above the threshold as anomalies\n","anomalies = reconstruction_error > threshold\n","\n","print(time.time() - start_time)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9JsRhH8LUuS"},"outputs":[],"source":["import pickle\n","import torch\n","\n","\n","with open(\"tgn_node_embeddings/LSTM_TGN_reddit_node_embeddings.pkl\", \"wb\") as f:\n","    pickle.dump(final_embeddings_numpy, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zB_A-9XUX42b"},"outputs":[],"source":["import pickle\n","import torch\n","with open(\"tgn_node_embeddings/LSTM_TGN_reddit_node_embeddings.pkl\", \"rb\") as f:\n","    final_embeddings_numpy = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzUbAAsNfaNz"},"outputs":[],"source":["import numpy as np\n","\n","\n","\n","loaded_dict['pred']['lstmTGN'] = lstm_tgn_pred\n","loaded_dict['prob']['lstmTGN'] = lstm_tgn_prob\n","loaded_dict['roc_scores']['lstmTGN'] = lstm_tgn_roc\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUIa_G5mr84w"},"outputs":[],"source":["with open('data/reddit_bond_results.pkl', 'wb') as file:\n","    pickle.dump(loaded_dict, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IQYAULFxfcxU"},"outputs":[],"source":["predicted_list = [int(value) for value in anomalies]\n","true_labels = [0 if x == 0 else 1 for x in list(data.y)]\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1WFUXrsnDN7C"},"source":["# ENRON"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVfjjSfFKy0r"},"outputs":[],"source":["from pygod.utils import load_data\n","data = load_data('enron')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1712193632959,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"N7SXXSnHw6QB","outputId":"38e1cb57-6eb7-4f94-b479-2d5d345abc98"},"outputs":[{"data":{"text/plain":["Data(x=[13533, 18], edge_index=[2, 176987], y=[13533])"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9918277,"status":"ok","timestamp":1712131608038,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"0qMhVFEHRTkA","outputId":"7a5c0876-d2f4-4df6-c891-d54061de7fe4"},"outputs":[],"source":["roc_scores, pred, prob, timing, memory_consumption = bond_pipeline(data)\n","\n","import pickle\n","filename = 'data/enron_bond_results.pkl'\n","\n","# Open the file in binary write mode and save (pickle) the dictionary\n","my_dict = {'roc_scores': roc_scores, 'pred': pred, 'prob': prob, 'timing': timing, 'memory_consumption': memory_consumption}\n","with open(filename, 'wb') as file:\n","    pickle.dump(my_dict, file)"]},{"cell_type":"markdown","metadata":{"id":"szNgyduLenDe"},"source":["## TGN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeWYoY1ljilA"},"outputs":[],"source":["from datetime import datetime\n","import numpy as np\n","import torch\n","from torch_geometric.data import Data\n","setup_seed(42)\n","\n","start_date = datetime(1999, 1, 1)\n","end_date = datetime(2002, 12, 31)\n","\n","# Calculate total biweekly periods\n","total_biweeks = ((end_date - start_date).days // 14) + 1\n","\n","def generate_weighted_random_biweeks(total_biweeks, key_periods_weights):\n","    biweeks = np.arange(total_biweeks)\n","    weights = np.ones(total_biweeks)\n","\n","    for period, weight in key_periods_weights.items():\n","        # Adjust period to biweekly\n","        start_biweek, end_biweek = period[0] // 2, period[1] // 2\n","        weights[start_biweek:end_biweek] = weight\n","\n","    weights /= weights.sum()\n","\n","    return np.random.choice(biweeks, size=(data.edge_index.size(1),), p=weights)\n","\n","# Adjust weights for biweekly. The periods need to be updated to reflect biweekly intervals.\n","key_periods_weights = {\n","    (0, 26): 2,  # Adjusted for biweekly\n","    (52, 78): 3,  # Adjusted for biweekly\n","}\n","\n","timestamps = generate_weighted_random_biweeks(total_biweeks, key_periods_weights)\n","\n","def create_biweekly_incremental_snapshots(data, timestamps, total_biweeks):\n","    snapshots = []\n","    accumulated_edges = torch.empty((2, 0), dtype=torch.long)\n","\n","    for biweek in range(total_biweeks):\n","        # Select edges that fall into the current biweek\n","        mask = timestamps == biweek\n","        new_edges_biweek = data.edge_index[:, mask]\n","\n","        # Accumulate edges up to the current biweek\n","        if new_edges_biweek.size(1) > 0:\n","            accumulated_edges = torch.cat([accumulated_edges, new_edges_biweek], dim=1)\n","\n","        # Ensure nodes are accumulated based on edges up to the current biweek\n","        if accumulated_edges.size(1) > 0:\n","            accumulated_nodes = torch.unique(accumulated_edges)\n","            sub_data = Data(edge_index=accumulated_edges, num_nodes=accumulated_nodes.max().item() + 1)\n","            if data.x is not None:\n","                sub_data.x = data.x[accumulated_nodes]\n","            snapshots.append(sub_data)\n","\n","    return snapshots\n","\n","# Make sure to adjust 'data' and 'total_biweeks' appropriately before calling this function.\n","snapshots = create_biweekly_incremental_snapshots(data, timestamps, total_biweeks)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1712193638523,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"PF0-TDKM_2Wz","outputId":"9fd19d61-bf3f-46a9-9a6f-da60e7e25f2d"},"outputs":[{"data":{"text/plain":["[Data(edge_index=[2, 166086], num_nodes=13533, x=[13303, 18]),\n"," Data(edge_index=[2, 167273], num_nodes=13533, x=[13327, 18]),\n"," Data(edge_index=[2, 168491], num_nodes=13533, x=[13355, 18]),\n"," Data(edge_index=[2, 169709], num_nodes=13533, x=[13389, 18]),\n"," Data(edge_index=[2, 170860], num_nodes=13533, x=[13411, 18]),\n"," Data(edge_index=[2, 172123], num_nodes=13533, x=[13436, 18]),\n"," Data(edge_index=[2, 173376], num_nodes=13533, x=[13462, 18]),\n"," Data(edge_index=[2, 174541], num_nodes=13533, x=[13486, 18]),\n"," Data(edge_index=[2, 175758], num_nodes=13533, x=[13507, 18]),\n"," Data(edge_index=[2, 176987], num_nodes=13533, x=[13533, 18])]"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["snapshots[-10:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJPfsnIlkaEv"},"outputs":[],"source":["import torch\n","from torch_geometric.data import Data\n","import torch\n","\n","def reindex_nodes(data_snapshot):\n","    \"\"\"\n","    Adjusts edge_index and x to ensure node indices are continuous and synchronized.\n","    :param data_snapshot: A Data object containing x (node features) and edge_index.\n","    :return: A new Data object with adjusted edge_index and potentially x.\n","    \"\"\"\n","    unique_nodes, new_indices = torch.unique(data_snapshot.edge_index, return_inverse=True)\n","    num_nodes = data_snapshot.x.size(0)\n","\n","    # Initialize a new x if necessary\n","    if len(unique_nodes) != num_nodes:\n","        new_x = torch.zeros((len(unique_nodes), data_snapshot.x.size(1)), dtype=data_snapshot.x.dtype)\n","        new_x[unique_nodes] = data_snapshot.x[:len(unique_nodes)]\n","    else:\n","        new_x = data_snapshot.x\n","\n","    # Reshape new_indices to match the shape of edge_index\n","    new_edge_index = new_indices.view(data_snapshot.edge_index.size())\n","\n","    return Data(x=new_x, edge_index=new_edge_index, y=data_snapshot.y if hasattr(data_snapshot, 'y') else None)\n","\n","\n","reindexed_snapshots = [reindex_nodes(snapshot) for snapshot in snapshots]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZrOHms6Uk2Fm"},"outputs":[],"source":["num_snapshots = 0\n","for snap in reindexed_snapshots:\n","  num_snapshots+=1\n","\n","\n","node_features_dim = 18\n","hidden_dim = 200\n","\n","learning_rate = 0.01\n","total_nodes = 13533\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128,"status":"ok","timestamp":1712193646433,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"QVmYzSu6ofel","outputId":"f2edeed2-b312-4687-edba-7ca873995c63"},"outputs":[{"data":{"text/plain":["105"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["num_snapshots"]},{"cell_type":"markdown","metadata":{"id":"C_4IAHSw8S49"},"source":["### Normal TGN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52713,"status":"ok","timestamp":1712193991010,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"FFevW_NW8R-K","outputId":"7fb97467-cf64-46a3-865e-c5244452c770"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 completed\n","Epoch 1 completed\n","Epoch 2 completed\n","Epoch 3 completed\n","Epoch 4 completed\n","Time (enron normal tgn): 51.741729736328125\n","Max memory usage (enron normal tgn): 272109 KiB\n"]}],"source":["import torch\n","from torch.nn import Module\n","from torch_geometric_temporal.nn.recurrent import GConvGRU\n","setup_seed(42)\n","\n","gc.collect()\n","tracemalloc.start()\n","\n","start_time = time.time()\n","\n","start_mem = memory_usage(-1, interval=0.1, timeout=1)\n","\n","\n","class CustomTemporalModel(Module):\n","    def __init__(self, node_features_dim, hidden_dim, total_nodes):\n","        super(CustomTemporalModel, self).__init__()\n","        self.gconv_gru = GConvGRU(node_features_dim, hidden_dim, 1)\n","        self.total_nodes = total_nodes\n","        self.node_embedding = torch.nn.Embedding(num_embeddings=total_nodes, embedding_dim=hidden_dim)\n","        # Initialize embeddings to zero\n","        self.node_embedding.weight.data = torch.zeros(total_nodes, hidden_dim)\n","\n","    def forward(self, snapshot_batches):\n","        presence_mask = torch.zeros(self.total_nodes, dtype=torch.bool)\n","\n","        for x_tensor, edge_index_tensor in snapshot_batches:\n","            node_indices = edge_index_tensor.unique()\n","            presence_mask[node_indices] = True  # Update presence mask\n","\n","            embedding = self.gconv_gru(x_tensor, edge_index_tensor, None)\n","            self.node_embedding.weight.data[node_indices] = embedding\n","\n","\n","        aggregated_embeddings = self.node_embedding.weight.data[presence_mask]\n","\n","        return aggregated_embeddings\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = CustomTemporalModel(node_features_dim, hidden_dim, total_nodes).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","num_epochs = 5\n","model.train()\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    snapshot_batches = []\n","    for snapshot in reindexed_snapshots:\n","        x = snapshot.x.to(device)\n","        edge_index = snapshot.edge_index.to(device)\n","        snapshot_batches.append((x, edge_index))\n","\n","    aggregated_embeddings = model(snapshot_batches)\n","\n","    optimizer.step()\n","\n","    print(f'Epoch {epoch} completed')\n","\n","print('Time (enron normal tgn):',time.time() - start_time)\n","mem = tracemalloc.get_traced_memory()[-1]  # Calculate incremental memory usage\n","tracemalloc.stop()\n","print(f'Max memory usage (enron normal tgn): {mem} KiB')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gbkjg0qrDo_a"},"outputs":[],"source":["final_embeddings_numpy = aggregated_embeddings.cpu().detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8478,"status":"ok","timestamp":1712194017360,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"Dld6MdR_6iIQ","outputId":"fc23a99d-47ed-406e-f94f-22bfab7d5a78"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","43/43 [==============================] - 1s 9ms/step - loss: 0.1818 - val_loss: 0.0646\n","Epoch 2/25\n","43/43 [==============================] - 0s 7ms/step - loss: 0.0209 - val_loss: 0.0052\n","Epoch 3/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0030\n","Epoch 4/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0025\n","Epoch 5/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0022\n","Epoch 6/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0020\n","Epoch 7/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0018\n","Epoch 8/25\n","43/43 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0016\n","Epoch 9/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0016\n","Epoch 10/25\n","43/43 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0015\n","Epoch 11/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n","Epoch 12/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n","Epoch 13/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n","Epoch 14/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n","Epoch 15/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n","Epoch 16/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n","Epoch 17/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n","Epoch 18/25\n","43/43 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n","Epoch 19/25\n","43/43 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n","Epoch 20/25\n","43/43 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n","Epoch 21/25\n","43/43 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n","Epoch 22/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n","Epoch 23/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n","Epoch 24/25\n","43/43 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n","Epoch 25/25\n","43/43 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n","423/423 [==============================] - 1s 2ms/step\n","8.352466821670532\n"]}],"source":["from keras.layers import Input, Dense\n","from keras.models import Model\n","setup_seed(42)\n","\n","start_time = time.time()\n","\n","\n","# Define the size of our embeddings\n","input_dim = final_embeddings_numpy.shape[1]  # embedding_dimension\n","encoding_dim = 100 # or choose based on your dataset\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","\n","# Decoder\n","decoded = Dense(input_dim, activation='sigmoid')(encoded)\n","\n","# Autoencoder\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the model\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","setup_seed(42)\n","\n","\n","# Split the data\n","X_train, X_val = train_test_split(final_embeddings_numpy, test_size=0.2, random_state=42)\n","\n","\n","autoencoder.fit(X_train, X_train,\n","                epochs=25,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(X_val, X_val))\n","\n","# Reconstruct embeddings\n","setup_seed(42)\n","\n","reconstructed_embeddings = autoencoder.predict(final_embeddings_numpy)\n","\n","# Calculate mean squared error (MSE) as reconstruction error\n","reconstruction_error = np.mean(np.power(final_embeddings_numpy - reconstructed_embeddings, 2), axis=1)\n","\n","threshold = np.mean(reconstruction_error) + np.std(reconstruction_error)\n","# Flag embeddings with errors above the threshold as anomalies\n","anomalies = reconstruction_error > threshold\n","\n","print(time.time() - start_time)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dn-guim5ts7z"},"outputs":[],"source":["enron_scores['pred']['normal_tgn']=anomalies\n","enron_scores['prob']['normal_tgn']=reconstruction_error\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1712194020225,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"l-doJEhR7HbB","outputId":"c83b4511-3737-4db2-a511-143e6dd80044"},"outputs":[],"source":["predicted_list = [int(value) for value in anomalies]\n","true_labels = [0 if x == 0 else 1 for x in list(data.y)]\n","\n","from pygod.metric import eval_roc_auc, eval_f1\n","\n","roc_score = eval_roc_auc(data.y, reconstruction_error)\n","print('ROC Score:', roc_score)"]},{"cell_type":"markdown","metadata":{"id":"uWGmlw9ZlTkr"},"source":["### LSTM TGN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51530,"status":"ok","timestamp":1712193702757,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"VZYBo6h1lVsp","outputId":"4f97fc92-b7a7-43b1-c000-ca3dc19c77f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 completed\n","Epoch 1 completed\n","Time (enron lstm tgn): 50.3444390296936\n","Max memory usage (enron lstm tgn): 4791520 KiB\n"]}],"source":["\n","import torch\n","from torch.nn import Module, LSTM, GRUCell, Linear\n","from torch_geometric_temporal.nn.recurrent import GConvGRU\n","from torch.nn.functional import softmax\n","from torch_geometric.data import Data\n","from torch.nn import Embedding\n","from torch.nn.utils.rnn import pad_sequence\n","\n","setup_seed(42)\n","\n","gc.collect()\n","tracemalloc.start()\n","\n","start_time = time.time()\n","\n","start_mem = memory_usage(-1, interval=0.1, timeout=1)\n","\n","\n","class CustomTemporalModel(Module):\n","    def __init__(self, node_features_dim, hidden_dim, total_nodes, device,num_gconv_gru_layers=2, num_lstm_layers=2):\n","        super(CustomTemporalModel, self).__init__()\n","        self.device = device\n","        # self.gconv_gru = GConvGRU(node_features_dim, hidden_dim, 1).to(device)\n","        # self.lstm = LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True).to(device)\n","                # Stack multiple GConvGRU layers\n","\n","        self.num_gconv_gru_layers = num_gconv_gru_layers\n","        # self.num_lstm_layers = num_lstm_layers\n","\n","        self.gconv_gru = ModuleList([\n","            GConvGRU(node_features_dim if i == 0 else hidden_dim, hidden_dim, 1).to(device)\n","            for i in range(num_gconv_gru_layers)\n","        ])\n","\n","        # Use an LSTM with multiple layers\n","        self.lstm = LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True, num_layers=num_lstm_layers).to(device)\n","\n","        self.total_nodes = total_nodes\n","        self.hidden_dim = hidden_dim\n","        # Each node's embeddings across snapshots will be stored here\n","        self.node_embeddings_history = torch.zeros(total_nodes, 0, hidden_dim).to(device)\n","        self.node_embedding = torch.nn.Embedding(num_embeddings=total_nodes, embedding_dim=hidden_dim).to(device)\n","        # Initialize embeddings to zero\n","        self.node_embedding.weight.data = torch.zeros(total_nodes, hidden_dim).to(device)\n","\n","    def forward(self, snapshot_batches):\n","        presence_mask = torch.zeros(self.total_nodes, dtype=torch.bool).to(self.device)\n","\n","        # Temporary storage for the current snapshot's embeddings\n","        current_snapshot_embeddings = torch.zeros(self.total_nodes, self.hidden_dim).to(self.device)\n","\n","        for x_tensor, edge_index_tensor in snapshot_batches:\n","            node_indices = edge_index_tensor.unique()\n","            presence_mask[node_indices] = True  # Update presence mask\n","            embedding = x_tensor\n","            for gconv_gru in self.gconv_gru:\n","                embedding = gconv_gru(embedding, edge_index_tensor, None)\n","\n","            # embedding = self.gconv_gru(x_tensor, edge_index_tensor, None)\n","            current_snapshot_embeddings[node_indices] = embedding\n","\n","        # Update the history of embeddings with the current snapshot's embeddings\n","        # Add an extra dimension for \"sequence length\" to match LSTM input\n","        current_snapshot_embeddings = current_snapshot_embeddings.unsqueeze(1)\n","        self.node_embeddings_history = torch.cat((self.node_embeddings_history, current_snapshot_embeddings), dim=1)\n","\n","        # Use LSTM to process the temporal sequence of embeddings for each node\n","        lstm_out, (hn, cn) = self.lstm(self.node_embeddings_history)\n","\n","        aggregated_embeddings = hn[-1]\n","\n","\n","        # The last hidden state `hn` represents the aggregated embedding considering the temporal dimension\n","        aggregated_embeddings = hn.squeeze(0)  # Remove the first dimension for batch\n","\n","        if aggregated_embeddings.dim() == 3:  # When it's (batch, nodes, features)\n","    # Selecting the embeddings of present nodes across all batches\n","            aggregated_embeddings = aggregated_embeddings[:, presence_mask, :]\n","        elif aggregated_embeddings.dim() == 2:  # When it's (nodes, features)\n","            aggregated_embeddings = aggregated_embeddings[presence_mask]\n","        # Use the presence_mask to filter embeddings of nodes that were present at least once\n","        # aggregated_embeddings = aggregated_embeddings[presence_mask]\n","\n","        return aggregated_embeddings\n","\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cpu\")\n","\n","model = CustomTemporalModel(node_features_dim, hidden_dim, total_nodes, device).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","num_epochs = 2\n","model.train()\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    snapshot_batches = []\n","    for snapshot in reindexed_snapshots:\n","        x = snapshot.x.to(device)\n","        edge_index = snapshot.edge_index.to(device)\n","        snapshot_batches.append((x, edge_index))\n","\n","    aggregated_embeddings = model(snapshot_batches)\n","\n","    optimizer.step()\n","\n","    print(f'Epoch {epoch} completed')\n","\n","\n","print('Time (enron lstm tgn):',time.time() - start_time)\n","mem = tracemalloc.get_traced_memory()[-1]  # Calculate incremental memory usage\n","tracemalloc.stop()\n","print(f'Max memory usage (enron lstm tgn): {mem} KiB')\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mm_vtJ0ulbgp"},"outputs":[],"source":["final_embeddings_numpy = aggregated_embeddings.cpu().detach().numpy()[-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12232,"status":"ok","timestamp":1712193726539,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"KyBOc--97RBY","outputId":"b16262a6-c801-4d56-d5b4-68a9aba597f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","43/43 [==============================] - 1s 9ms/step - loss: 0.2093 - val_loss: 0.1317\n","Epoch 2/25\n","43/43 [==============================] - 0s 5ms/step - loss: 0.0605 - val_loss: 0.0167\n","Epoch 3/25\n","43/43 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0047\n","Epoch 4/25\n","43/43 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0025\n","Epoch 5/25\n","43/43 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0017\n","Epoch 6/25\n","43/43 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n","Epoch 7/25\n","43/43 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n","Epoch 8/25\n","43/43 [==============================] - 0s 5ms/step - loss: 9.3776e-04 - val_loss: 8.5965e-04\n","Epoch 9/25\n","43/43 [==============================] - 0s 6ms/step - loss: 8.0346e-04 - val_loss: 7.4895e-04\n","Epoch 10/25\n","43/43 [==============================] - 0s 5ms/step - loss: 7.0846e-04 - val_loss: 6.6857e-04\n","Epoch 11/25\n","43/43 [==============================] - 0s 5ms/step - loss: 6.3820e-04 - val_loss: 6.0791e-04\n","Epoch 12/25\n","43/43 [==============================] - 0s 5ms/step - loss: 5.8438e-04 - val_loss: 5.6068e-04\n","Epoch 13/25\n","43/43 [==============================] - 0s 5ms/step - loss: 5.4199e-04 - val_loss: 5.2299e-04\n","Epoch 14/25\n","43/43 [==============================] - 0s 5ms/step - loss: 5.0783e-04 - val_loss: 4.9232e-04\n","Epoch 15/25\n","43/43 [==============================] - 0s 5ms/step - loss: 4.7980e-04 - val_loss: 4.6691e-04\n","Epoch 16/25\n","43/43 [==============================] - 0s 5ms/step - loss: 4.5643e-04 - val_loss: 4.4558e-04\n","Epoch 17/25\n","43/43 [==============================] - 0s 5ms/step - loss: 4.3669e-04 - val_loss: 4.2745e-04\n","Epoch 18/25\n","43/43 [==============================] - 0s 5ms/step - loss: 4.1983e-04 - val_loss: 4.1188e-04\n","Epoch 19/25\n","43/43 [==============================] - 0s 5ms/step - loss: 4.0528e-04 - val_loss: 3.9838e-04\n","Epoch 20/25\n","43/43 [==============================] - 0s 5ms/step - loss: 3.9262e-04 - val_loss: 3.8658e-04\n","Epoch 21/25\n","43/43 [==============================] - 0s 5ms/step - loss: 3.8152e-04 - val_loss: 3.7618e-04\n","Epoch 22/25\n","43/43 [==============================] - 0s 5ms/step - loss: 3.7170e-04 - val_loss: 3.6697e-04\n","Epoch 23/25\n","43/43 [==============================] - 0s 5ms/step - loss: 3.6298e-04 - val_loss: 3.5875e-04\n","Epoch 24/25\n","43/43 [==============================] - 0s 5ms/step - loss: 3.5517e-04 - val_loss: 3.5138e-04\n","Epoch 25/25\n","43/43 [==============================] - 0s 5ms/step - loss: 3.4816e-04 - val_loss: 3.4474e-04\n","423/423 [==============================] - 1s 2ms/step\n","12.221368312835693\n"]}],"source":["from keras.layers import Input, Dense\n","from keras.models import Model\n","setup_seed(42)\n","\n","start_time = time.time()\n","\n","\n","# Define the size of our embeddings\n","input_dim = final_embeddings_numpy.shape[1]  # embedding_dimension\n","encoding_dim = 100 # or choose based on your dataset\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","\n","# Decoder\n","decoded = Dense(input_dim, activation='sigmoid')(encoded)\n","\n","# Autoencoder\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the model\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","setup_seed(42)\n","\n","\n","# Split the data\n","X_train, X_val = train_test_split(final_embeddings_numpy, test_size=0.2, random_state=42)\n","\n","\n","autoencoder.fit(X_train, X_train,\n","                epochs=25,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(X_val, X_val))\n","\n","# Reconstruct embeddings\n","setup_seed(42)\n","\n","reconstructed_embeddings = autoencoder.predict(final_embeddings_numpy)\n","\n","# Calculate mean squared error (MSE) as reconstruction error\n","reconstruction_error = np.mean(np.power(final_embeddings_numpy - reconstructed_embeddings, 2), axis=1)\n","\n","threshold = np.mean(reconstruction_error) + np.std(reconstruction_error)\n","threshold = 0.00043931\n","# Flag embeddings with errors above the threshold as anomalies\n","anomalies = reconstruction_error > threshold\n","\n","print(time.time() - start_time)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZxcVD_ys8VY"},"outputs":[],"source":["with open(\"data/weibo_bond_results.pkl\", \"rb\") as f:\n","    enron_scores = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"El65kYpDtIi9"},"outputs":[],"source":["enron_scores['pred']['lstm_tgn']=anomalies\n","enron_scores['prob']['lstm_tgn']=reconstruction_error\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUoVVt2Vt-FK"},"outputs":[],"source":["with open('data/weibo_bond_results.pkl', 'wb') as file:\n","    pickle.dump(enron_scores, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1710990369789,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"YzNEJ_DB8ts-","outputId":"04995e32-5209-48be-8774-ea1ab6378321"},"outputs":[],"source":["from pygod.metric import eval_roc_auc, eval_f1\n","\n","roc_score = eval_roc_auc(data.y, reconstruction_error)\n","print('ROC Score:', roc_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tp76OEQM7nrT"},"outputs":[],"source":["import pickle\n","import torch\n","\n","\n","with open(\"tgn_node_embeddings/LSTM_TGN_enron_node_embeddings.pkl\", \"wb\") as f:\n","    pickle.dump(final_embeddings_numpy, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1710387830951,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"5n-Msnx3LSd7","outputId":"db701858-c209-4106-bdaa-ec4eadffbbfc"},"outputs":[{"data":{"text/plain":["array([[-0.00221765,  0.01705775, -0.03676904, ...,  0.00329873,\n","        -0.02648609, -0.03650445],\n","       [-0.00221765,  0.01705775, -0.03676904, ...,  0.00329873,\n","        -0.02648609, -0.03650445],\n","       [-0.00243468,  0.01773392, -0.03706658, ...,  0.00351605,\n","        -0.02645797, -0.03621674],\n","       ...,\n","       [-0.00262048,  0.01969066, -0.03787835, ...,  0.00378438,\n","        -0.02528247, -0.03392569],\n","       [-0.00265102,  0.01972638, -0.03789289, ...,  0.00380341,\n","        -0.0252875 , -0.03389958],\n","       [-0.00221944,  0.01706246, -0.03677114, ...,  0.00330049,\n","        -0.02648666, -0.03650363]], dtype=float32)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["final_embeddings_numpy[:10]"]},{"cell_type":"markdown","metadata":{"id":"ovMykwZFPjTJ"},"source":["# DRGAPHFIN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18244,"status":"ok","timestamp":1712858742144,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"rbYr3L7UwiEX","outputId":"07bae0d1-3adc-4ef3-cca6-12d91fe4d36b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvzUKj3EAvOL"},"outputs":[],"source":["from torch_geometric.datasets import DGraphFin\n","\n","dataset = DGraphFin(root='/data')\n","data = dataset[0]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1712294007368,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"aMV1bdQLmG9T","outputId":"ce757d0b-65ba-4674-d5ae-8b1c90183210"},"outputs":[{"data":{"text/plain":["Data(x=[3700550, 17], edge_index=[2, 4300999], y=[3700550], edge_type=[4300999], edge_time=[4300999], train_mask=[3700550], val_mask=[3700550], test_mask=[3700550])"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vcHCYnbDS18L"},"outputs":[],"source":["import torch\n","from torch_geometric.data import Data\n","\n","# Assuming 'data' is your PyTorch Geometric Data object\n","\n","# Step 1: Sort edges by 'edge_time'\n","sorted_indices = data.edge_time.argsort()\n","sorted_edge_index = data.edge_index[:, sorted_indices]\n","sorted_edge_time = data.edge_time[sorted_indices]\n","sorted_edge_type = data.edge_type[sorted_indices]\n","\n","# Step 2: Identify the first 10 unique 'edge_time' values\n","unique_edge_times = sorted_edge_time.unique()[:5]\n","\n","# Step 3: Create incremental snapshots\n","snapshots = []\n","for time in unique_edge_times:\n","    # Identify edges up to the current 'edge_time'\n","    valid_edges_mask = sorted_edge_time <= time\n","    current_edge_index = sorted_edge_index[:, valid_edges_mask]\n","    current_edge_type = sorted_edge_type[valid_edges_mask]\n","\n","    involved_nodes = current_edge_index.unique()\n","\n","    # Extract features for involved nodes\n","    current_x = data.x[involved_nodes]\n","    current_y = data.y[involved_nodes]\n","\n","    # Create a snapshot Data object\n","    snapshot = Data(x=current_x, edge_index=current_edge_index, y=current_y,\n","                    edge_type=current_edge_type, edge_time=time,\n","                    train_mask=None, val_mask=None, test_mask=None)  # Update masks as needed\n","    snapshots.append(snapshot)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1712294008226,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"ua7hg2kAlNDr","outputId":"1e76b37d-3ab4-4496-cd90-ea25f180c439"},"outputs":[{"data":{"text/plain":["[Data(x=[8958, 17], edge_index=[2, 4604], y=[8958], edge_type=[4604], edge_time=1),\n"," Data(x=[17641, 17], edge_index=[2, 9242], y=[17641], edge_type=[9242], edge_time=2),\n"," Data(x=[25987, 17], edge_index=[2, 13823], y=[25987], edge_type=[13823], edge_time=3),\n"," Data(x=[34383, 17], edge_index=[2, 18512], y=[34383], edge_type=[18512], edge_time=4),\n"," Data(x=[42507, 17], edge_index=[2, 23179], y=[42507], edge_type=[23179], edge_time=5)]"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["snapshots"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":414,"status":"ok","timestamp":1712294009354,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"YbWvxhGVRTt6","outputId":"c44801e9-361f-456c-80b4-93ed967ccf1c"},"outputs":[{"data":{"text/plain":["Counter({2: 16579, 3: 10740, 0: 14874, 1: 314})"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["int_list = [t.item() for t in list(snapshots[-1].y)]\n","from collections import Counter\n","\n","items_count = Counter(int_list)\n","items_count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9sdiRX11ozed"},"outputs":[],"source":["y_values = [int(value) for value in snapshots[-1].y]\n","y_values = [1 if x == 1 else 0 for x in y_values]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQXiVvLmqk2J"},"outputs":[],"source":["import torch\n","from torch_geometric.data import Data\n","import torch\n","\n","def reindex_nodes(data_snapshot):\n","    \"\"\"\n","    Adjusts edge_index and x to ensure node indices are continuous and synchronized.\n","    :param data_snapshot: A Data object containing x (node features) and edge_index.\n","    :return: A new Data object with adjusted edge_index and potentially x.\n","    \"\"\"\n","    unique_nodes, new_indices = torch.unique(data_snapshot.edge_index, return_inverse=True)\n","    num_nodes = data_snapshot.x.size(0)\n","\n","    # Initialize a new x if necessary\n","    if len(unique_nodes) != num_nodes:\n","        new_x = torch.zeros((len(unique_nodes), data_snapshot.x.size(1)), dtype=data_snapshot.x.dtype)\n","        new_x[unique_nodes] = data_snapshot.x[:len(unique_nodes)]\n","    else:\n","        new_x = data_snapshot.x\n","\n","    # Reshape new_indices to match the shape of edge_index\n","    new_edge_index = new_indices.view(data_snapshot.edge_index.size())\n","\n","    return Data(x=new_x, edge_index=new_edge_index, y=data_snapshot.y if hasattr(data_snapshot, 'y') else None)\n","\n","reindexed_snapshots = [reindex_nodes(snapshot) for snapshot in snapshots]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":122,"status":"ok","timestamp":1712294012641,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"-y2hDWvTqpr6","outputId":"3186d34e-c159-4283-90a6-eb81cde43305"},"outputs":[{"data":{"text/plain":["[Data(x=[8958, 17], edge_index=[2, 4604], y=[8958]),\n"," Data(x=[17641, 17], edge_index=[2, 9242], y=[17641]),\n"," Data(x=[25987, 17], edge_index=[2, 13823], y=[25987]),\n"," Data(x=[34383, 17], edge_index=[2, 18512], y=[34383]),\n"," Data(x=[42507, 17], edge_index=[2, 23179], y=[42507])]"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["reindexed_snapshots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E4vS4HpphXHJ"},"outputs":[],"source":["with open(\"data/dgraph_bond_results.pkl\", \"rb\") as f:\n","    dgraph = pickle.load(f)"]},{"cell_type":"markdown","metadata":{"id":"yij0pPyVoi4J"},"source":["### ALL DATA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"onDbeBpbStOx"},"outputs":[],"source":["# import torch\n","# from torch_geometric.data import Data\n","\n","# def create_incremental_snapshots(data, total_snapshots=821, target_snapshots=82):\n","#     # Calculate the range of each bin\n","#     bin_size = total_snapshots // target_snapshots\n","\n","#     # Initialize a list to hold the Data objects for each new snapshot\n","#     snapshots = [None] * target_snapshots\n","\n","#     # Initialize containers for incremental construction of snapshots\n","#     edge_index_accumulated = torch.empty((2, 0), dtype=torch.long)\n","#     unique_nodes = set()\n","\n","#     # Function to update the incremental snapshot\n","#     def update_snapshot(bin_index, edge_index):\n","#         nonlocal edge_index_accumulated, unique_nodes\n","#         # Add current edges to the accumulated edge index\n","#         edge_index_accumulated = torch.cat([edge_index_accumulated, edge_index], dim=1)\n","#         # Update unique nodes\n","#         unique_nodes.update(edge_index[0].tolist())\n","#         unique_nodes.update(edge_index[1].tolist())\n","#         # Create a new Data object with the accumulated edges and nodes\n","#         data_snapshot = Data(edge_index=edge_index_accumulated, num_nodes=len(unique_nodes))\n","#         snapshots[bin_index] = data_snapshot\n","\n","#     # Iterate through each edge to determine its bin and update the snapshot\n","#     for edge_index, edge_time in zip(data.edge_index.t(), data.edge_time):\n","#         bin_index = min(edge_time // bin_size, target_snapshots - 1)  # Determine bin index\n","#         update_snapshot(bin_index, edge_index.view(2, -1))\n","\n","#     return snapshots\n","\n","# snapshots = create_incremental_snapshots(data)\n","\n","# import torch\n","\n","# # Assuming `snapshots` is your list of PyTorch Geometric Data objects\n","# # Save the snapshots list to a file\n","# torch.save(snapshots, '/content/drive/MyDrive/THESIS/First experiment - PyGOD/data/snapshots.pt')\n","\n","# snapshots[-20:]\n"]},{"cell_type":"markdown","metadata":{"id":"OvKsD8geoaUz"},"source":["## TGN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R1LXNwgQpWPW"},"outputs":[],"source":["from torch_geometric.nn import GCNConv\n","num_snapshots = 0\n","for snap in snapshots:\n","  num_snapshots+=1\n","\n","\n","node_features_dim = 17\n","hidden_dim = 200\n","\n","num_epochs = 5\n","learning_rate = 0.01\n","# max_node_index = max(snapshot.edge_index.max().item() for snapshot in snapshots)\n","# total_nodes = max_node_index   # Assuming node indices start at 0\n","total_nodes = 42507  # Make sure this is the maximum number of nodes in any snapshot\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fC5RfLo1rSCH"},"source":["### Normal TGN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3988,"status":"ok","timestamp":1712291185083,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"ZG8_i-ZOQSvd","outputId":"a6944fee-07ce-45fe-b87f-2ef1ae24a43d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 completed\n","Epoch 1 completed\n","Epoch 2 completed\n","Epoch 3 completed\n","Epoch 4 completed\n","Time (dgraphfin normal tgn): 3.3107264041900635\n","Max memory usage (dgraphfin normal tgn): 260447 KiB\n"]}],"source":["\n","import torch\n","from torch.nn import Module\n","from torch_geometric_temporal.nn.recurrent import GConvGRU\n","import time\n","import tracemalloc\n","import gc\n","setup_seed(42)\n","\n","gc.collect()\n","tracemalloc.start()\n","start_time = time.time()\n","\n","\n","class CustomTemporalModel(Module):\n","    def __init__(self, node_features_dim, hidden_dim, total_nodes):\n","        super(CustomTemporalModel, self).__init__()\n","        self.gconv_gru = GConvGRU(node_features_dim, hidden_dim, 1)\n","        self.total_nodes = total_nodes\n","        self.node_embedding = torch.nn.Embedding(num_embeddings=total_nodes, embedding_dim=hidden_dim)\n","        # Initialize embeddings to zero\n","        self.node_embedding.weight.data = torch.zeros(total_nodes, hidden_dim)\n","\n","    def forward(self, snapshot_batches):\n","        presence_mask = torch.zeros(self.total_nodes, dtype=torch.bool)\n","\n","        for x_tensor, edge_index_tensor in snapshot_batches:\n","            node_indices = edge_index_tensor.unique()\n","            presence_mask[node_indices] = True  # Update presence mask\n","\n","            embedding = self.gconv_gru(x_tensor, edge_index_tensor, None)\n","            # Update embeddings for nodes in the current snapshot\n","            self.node_embedding.weight.data[node_indices] = embedding\n","\n","        # Use the presence_mask to calculate a weighted average or another sophisticated aggregation\n","        # Here, you need to decide how to aggregate taking presence_mask into account\n","        # For example, simply ignoring non-present nodes:\n","        aggregated_embeddings = self.node_embedding.weight.data[presence_mask]\n","\n","        return aggregated_embeddings\n","\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = CustomTemporalModel(node_features_dim, hidden_dim, total_nodes).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","num_epochs = 5\n","model.train()\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    snapshot_batches = []\n","    for snapshot in reindexed_snapshots:\n","        x = snapshot.x.to(device)\n","        edge_index = snapshot.edge_index.to(device)\n","        snapshot_batches.append((x, edge_index))\n","\n","    aggregated_embeddings = model(snapshot_batches)\n","\n","    optimizer.step()\n","\n","    print(f'Epoch {epoch} completed')\n","\n","print('Time (dgraphfin normal tgn):',time.time() - start_time)\n","mem = tracemalloc.get_traced_memory()[-1]  # Calculate incremental memory usage\n","tracemalloc.stop()\n","print(f'Max memory usage (dgraphfin normal tgn): {mem} KiB')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":192,"status":"ok","timestamp":1712292334582,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"ewWkXeyWcie3","outputId":"eb965cc7-ee24-4284-b59e-e98a3832df04"},"outputs":[{"data":{"text/plain":["(42507, 200)"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["final_embeddings_numpy = aggregated_embeddings.detach().numpy()\n","final_embeddings_numpy.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BXflkM3k2iM"},"outputs":[],"source":["\n","with open(\"tgn_node_embeddings/LSTM_TGN_dgraph_node_embeddings.pkl\", \"wb\") as f:\n","    pickle.dump(final_embeddings_numpy, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22166,"status":"ok","timestamp":1712291216857,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"fG1N8a_OpkQy","outputId":"117fb4bd-9c51-41e6-f4b9-8774805b3bdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","133/133 [==============================] - 1s 6ms/step - loss: 0.0836 - val_loss: 0.0356\n","Epoch 2/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0336 - val_loss: 0.0318\n","Epoch 3/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0317 - val_loss: 0.0310\n","Epoch 4/25\n","133/133 [==============================] - 1s 5ms/step - loss: 0.0312 - val_loss: 0.0307\n","Epoch 5/25\n","133/133 [==============================] - 1s 5ms/step - loss: 0.0309 - val_loss: 0.0305\n","Epoch 6/25\n","133/133 [==============================] - 1s 5ms/step - loss: 0.0308 - val_loss: 0.0304\n","Epoch 7/25\n","133/133 [==============================] - 1s 5ms/step - loss: 0.0307 - val_loss: 0.0302\n","Epoch 8/25\n","133/133 [==============================] - 1s 5ms/step - loss: 0.0305 - val_loss: 0.0302\n","Epoch 9/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0305 - val_loss: 0.0301\n","Epoch 10/25\n","133/133 [==============================] - 1s 5ms/step - loss: 0.0304 - val_loss: 0.0301\n","Epoch 11/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0304 - val_loss: 0.0300\n","Epoch 12/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0303 - val_loss: 0.0300\n","Epoch 13/25\n","133/133 [==============================] - 1s 5ms/step - loss: 0.0303 - val_loss: 0.0300\n","Epoch 14/25\n","133/133 [==============================] - 1s 5ms/step - loss: 0.0303 - val_loss: 0.0299\n","Epoch 15/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0302 - val_loss: 0.0299\n","Epoch 16/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0302 - val_loss: 0.0299\n","Epoch 17/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0302 - val_loss: 0.0299\n","Epoch 18/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0302 - val_loss: 0.0298\n","Epoch 19/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0302 - val_loss: 0.0298\n","Epoch 20/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0301 - val_loss: 0.0298\n","Epoch 21/25\n","133/133 [==============================] - 1s 5ms/step - loss: 0.0301 - val_loss: 0.0298\n","Epoch 22/25\n","133/133 [==============================] - 1s 5ms/step - loss: 0.0301 - val_loss: 0.0298\n","Epoch 23/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0301 - val_loss: 0.0298\n","Epoch 24/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0301 - val_loss: 0.0298\n","Epoch 25/25\n","133/133 [==============================] - 1s 5ms/step - loss: 0.0301 - val_loss: 0.0297\n","1329/1329 [==============================] - 2s 2ms/step\n","21.68363666534424\n"]}],"source":["final_embeddings_numpy = aggregated_embeddings.detach().numpy()\n","from keras.layers import Input, Dense\n","from keras.models import Model\n","setup_seed(42)\n","\n","start_time = time.time()\n","\n","# Define the size of our embeddings\n","input_dim = final_embeddings_numpy.shape[1]  # embedding_dimension\n","encoding_dim = 100 # or choose based on your dataset\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","\n","# Decoder\n","decoded = Dense(input_dim, activation='sigmoid')(encoded)\n","\n","# Autoencoder\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the model\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","setup_seed(42)\n","\n","\n","# Split the data\n","X_train, X_val = train_test_split(final_embeddings_numpy, test_size=0.2, random_state=42)\n","\n","\n","autoencoder.fit(X_train, X_train,\n","                epochs=25,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(X_val, X_val))\n","\n","# Reconstruct embeddings\n","setup_seed(42)\n","\n","reconstructed_embeddings = autoencoder.predict(final_embeddings_numpy)\n","\n","# Calculate mean squared error (MSE) as reconstruction error\n","reconstruction_error = np.mean(np.power(final_embeddings_numpy - reconstructed_embeddings, 2), axis=1)\n","\n","threshold = np.mean(reconstruction_error) + np.std(reconstruction_error)\n","# Flag embeddings with errors above the threshold as anomalies\n","anomalies = reconstruction_error > threshold\n","\n","print(time.time() - start_time)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gEHlovnzhyN9"},"outputs":[],"source":["dgraph['pred']['normalTGN']=predicted_list\n","dgraph['prob']['normalTGN']=reconstruction_error\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8oZFvWki3pr"},"outputs":[],"source":["with open('data/dgraph_bond_results.pkl', 'wb') as file:\n","    pickle.dump(dgraph, file)"]},{"cell_type":"markdown","metadata":{"id":"kbK39heIrXIs"},"source":["### LSTM TGN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19231,"status":"ok","timestamp":1711771979204,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"f2rKQrxdxC1i","outputId":"de297b92-8c69-4aa1-a3ca-0b386a30659e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 completed\n","Epoch 1 completed\n","Epoch 2 completed\n","Epoch 3 completed\n","Epoch 4 completed\n","Epoch 5 completed\n","Time (dgraphFin tgn lstm): 18.634819269180298\n","Max memory usage (dgraphFin lstm tgn): 7726785 KiB\n"]}],"source":["import torch\n","from torch.nn import Module, ModuleList, LSTM, Embedding, Dropout, BatchNorm1d\n","from torch.optim import Adam\n","\n","import time\n","import gc\n","import tracemalloc\n","setup_seed(42)\n","\n","gc.collect()\n","tracemalloc.start()\n","\n","start_time = time.time()\n","\n","import torch\n","from torch.nn import Module, LSTM, Linear, Embedding, ModuleList, functional as F\n","import torch\n","from torch.nn import Module, LSTM, Linear, Embedding, ModuleList, functional as F\n","\n","class CustomTemporalModel(Module):\n","    def __init__(self, node_features_dim, hidden_dim, lstm_hidden_dim, total_nodes, gconv_gru_layers=2, lstm_layers=1):\n","        super(CustomTemporalModel, self).__init__()\n","        self.gconv_gru_layers = gconv_gru_layers\n","        self.gconv_gru = GConvGRU(node_features_dim, hidden_dim, 1)\n","        self.lstm = LSTM(input_size=hidden_dim, hidden_size=lstm_hidden_dim, num_layers=lstm_layers, batch_first=True)\n","        self.temporal_attention = Linear(lstm_hidden_dim, 1)\n","        self.hidden_dim = hidden_dim\n","        self.lstm_hidden_dim = lstm_hidden_dim\n","        self.total_nodes = total_nodes\n","\n","    def forward(self, snapshot_batches):\n","        max_nodes = self.total_nodes\n","        # Create a tensor to hold padded embeddings for all snapshots, nodes, and features\n","        padded_embeddings = torch.zeros(len(snapshot_batches), max_nodes, self.hidden_dim, device=snapshot_batches[0][0].device)\n","\n","        for i, (x_tensor, edge_index_tensor) in enumerate(snapshot_batches):\n","            embedding = self.gconv_gru(x_tensor, edge_index_tensor, None)\n","            node_indices = edge_index_tensor.unique()\n","            padded_embeddings[i, node_indices] = embedding\n","\n","        # Reshape for LSTM: treat each node's embedding sequence as a batch\n","        lstm_input = padded_embeddings.permute(1, 0, 2)  # Now shape is [nodes, snapshots, features]\n","        lstm_out, _ = self.lstm(lstm_input)\n","\n","        # Apply temporal attention to each node\n","        attention_weights = F.softmax(self.temporal_attention(lstm_out).squeeze(-1), dim=1)\n","        attended_embeddings = torch.bmm(attention_weights.unsqueeze(1), lstm_out).squeeze(1)\n","\n","        # Split embeddings into list of tensors, one per snapshot\n","        aggregated_embeddings = torch.split(attended_embeddings, 1, dim=0)  # Splitting by nodes, adjust if needed\n","\n","        return aggregated_embeddings\n","\n","# Model initialization and other components remain similar\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","lstm_hidden_dim=200\n","hidden_dim = 200\n","model = CustomTemporalModel(node_features_dim, hidden_dim, lstm_hidden_dim,total_nodes).to(device)\n","\n","# model = CustomTemporalModel(node_features_dim, hidden_dim, lstm_hidden_dim, lstm_layers=1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","num_epochs = 6\n","# Training loop (simplified for brevity)\n","model.train()\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    snapshot_batches = []\n","    for snapshot in reindexed_snapshots:\n","        x = snapshot.x.to(device)\n","        edge_index = snapshot.edge_index.to(device)\n","        snapshot_batches.append((x, edge_index))\n","\n","    attended_embedding = model(snapshot_batches)\n","\n","    # Assume some loss calculation and backpropagation here\n","    optimizer.step()\n","\n","    print(f'Epoch {epoch} completed')\n","\n","\n","\n","\n","print('Time (dgraphFin tgn lstm):',time.time() - start_time)\n","mem = tracemalloc.get_traced_memory()[-1]\n","tracemalloc.stop()\n","print(f'Max memory usage (dgraphFin lstm tgn): {mem} KiB')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OCl-scKbyttt"},"outputs":[],"source":["aggregated_embeddings = attended_embedding\n","final_embeddings_numpy = torch.stack(aggregated_embeddings).detach().numpy()\n","final_embeddings_numpy = np.squeeze(final_embeddings_numpy, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7940,"status":"ok","timestamp":1711741680225,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"lv390RX1rYut","outputId":"ffa4bcb9-9db3-4773-f8ad-ed0aa3014f5c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 completed\n","Epoch 1 completed\n","Time (dgraphFin tgn lstm): 7.158951997756958\n","Max memory usage (dgraphFin lstm tgn): 356023 KiB\n"]}],"source":["import time\n","import gc\n","import tracemalloc\n","setup_seed(42)\n","\n","gc.collect()\n","tracemalloc.start()\n","\n","start_time = time.time()\n","\n","\n","\n","class CustomTemporalModel(Module):\n","    def __init__(self, node_features_dim, hidden_dim, total_nodes, device,num_gconv_gru_layers=2, num_lstm_layers=1):\n","        super(CustomTemporalModel, self).__init__()\n","        self.device = device\n","\n","\n","        self.num_gconv_gru_layers = num_gconv_gru_layers\n","        self.num_lstm_layers = num_lstm_layers\n","\n","        self.gconv_gru = ModuleList([\n","            GConvGRU(node_features_dim if i == 0 else hidden_dim, hidden_dim, 1).to(device)\n","            for i in range(num_gconv_gru_layers)\n","        ])\n","        # self.gconv_gru = ModuleList([\n","        #     torch.nn.Sequential(\n","        #         GConvGRU(node_features_dim if i == 0 else hidden_dim, hidden_dim, 1),\n","        #         torch.nn.Dropout(p=0.2)  # Assuming a dropout rate of 20%\n","        #     ).to(device)\n","        #     for i in range(num_gconv_gru_layers)\n","        # ])\n","\n","        # Use an LSTM with multiple layers\n","        self.lstm = LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True, num_layers=num_lstm_layers).to(device)\n","\n","        self.total_nodes = total_nodes\n","        self.hidden_dim = hidden_dim\n","        # Each node's embeddings across snapshots will be stored here\n","        self.node_embeddings_history = torch.zeros(total_nodes, 0, hidden_dim).to(device)\n","        self.node_embedding = torch.nn.Embedding(num_embeddings=total_nodes, embedding_dim=hidden_dim).to(device)\n","        # Initialize embeddings to zero\n","        self.node_embedding.weight.data = torch.zeros(total_nodes, hidden_dim).to(device)\n","\n","    def forward(self, snapshot_batches):\n","        presence_mask = torch.zeros(self.total_nodes, dtype=torch.bool).to(self.device)\n","\n","        # Temporary storage for the current snapshot's embeddings\n","        current_snapshot_embeddings = torch.zeros(self.total_nodes, self.hidden_dim).to(self.device)\n","\n","        for x_tensor, edge_index_tensor in snapshot_batches:\n","            node_indices = edge_index_tensor.unique()\n","            presence_mask[node_indices] = True  # Update presence mask\n","            embedding = x_tensor\n","            for gconv_gru in self.gconv_gru:\n","                embedding = gconv_gru(embedding, edge_index_tensor)\n","\n","            # embedding = self.gconv_gru(x_tensor, edge_index_tensor, None)\n","            current_snapshot_embeddings[node_indices] = embedding\n","\n","        # Update the history of embeddings with the current snapshot's embeddings\n","        # Add an extra dimension for \"sequence length\" to match LSTM input\n","        current_snapshot_embeddings = current_snapshot_embeddings.unsqueeze(1)\n","        self.node_embeddings_history = torch.cat((self.node_embeddings_history, current_snapshot_embeddings), dim=1)\n","\n","        # Use LSTM to process the temporal sequence of embeddings for each node\n","        lstm_out, (hn, cn) = self.lstm(self.node_embeddings_history)\n","\n","        aggregated_embeddings = hn[-1]\n","\n","\n","        # The last hidden state `hn` represents the aggregated embedding considering the temporal dimension\n","        aggregated_embeddings = hn.squeeze(0)  # Remove the first dimension for batch\n","\n","        if aggregated_embeddings.dim() == 3:  # When it's (batch, nodes, features)\n","    # Selecting the embeddings of present nodes across all batches\n","            aggregated_embeddings = aggregated_embeddings[:, presence_mask, :]\n","        elif aggregated_embeddings.dim() == 2:  # When it's (nodes, features)\n","            aggregated_embeddings = aggregated_embeddings[presence_mask]\n","\n","\n","        return aggregated_embeddings\n","\n","\n","\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cpu\")\n","\n","model = CustomTemporalModel(node_features_dim, hidden_dim, total_nodes, device).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\n","\n","num_epochs = 2\n","model.train()\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    snapshot_batches = []\n","    for snapshot in reindexed_snapshots:\n","        x = snapshot.x.to(device)\n","        edge_index = snapshot.edge_index.to(device)\n","        snapshot_batches.append((x, edge_index))\n","\n","    aggregated_embeddings = model(snapshot_batches)[-1]\n","\n","    optimizer.step()\n","\n","    print(f'Epoch {epoch} completed')\n","\n","print('Time (dgraphFin tgn lstm):',time.time() - start_time)\n","mem = tracemalloc.get_traced_memory()[-1]\n","tracemalloc.stop()\n","print(f'Max memory usage (dgraphFin lstm tgn): {mem} KiB')\n","final_embeddings_numpy = aggregated_embeddings.detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30171,"status":"ok","timestamp":1711772029192,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"jq5jokN5sCRY","outputId":"5d3cd591-e686-44c1-fa9c-08204c2fab8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","133/133 [==============================] - 1s 6ms/step - loss: 0.0698 - val_loss: 0.0027\n","Epoch 2/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0019 - val_loss: 0.0014\n","Epoch 3/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0013 - val_loss: 0.0012\n","Epoch 4/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0011 - val_loss: 0.0011\n","Epoch 5/25\n","133/133 [==============================] - 1s 4ms/step - loss: 0.0011 - val_loss: 0.0010\n","Epoch 6/25\n","133/133 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 9.6192e-04\n","Epoch 7/25\n","133/133 [==============================] - 2s 15ms/step - loss: 9.0909e-04 - val_loss: 8.8138e-04\n","Epoch 8/25\n","133/133 [==============================] - 2s 13ms/step - loss: 8.5994e-04 - val_loss: 8.5702e-04\n","Epoch 9/25\n","133/133 [==============================] - 2s 12ms/step - loss: 8.4264e-04 - val_loss: 8.4296e-04\n","Epoch 10/25\n","133/133 [==============================] - 1s 11ms/step - loss: 8.2811e-04 - val_loss: 8.2784e-04\n","Epoch 11/25\n","133/133 [==============================] - 1s 11ms/step - loss: 8.1319e-04 - val_loss: 8.1280e-04\n","Epoch 12/25\n","133/133 [==============================] - 1s 10ms/step - loss: 7.9920e-04 - val_loss: 7.9913e-04\n","Epoch 13/25\n","133/133 [==============================] - 1s 10ms/step - loss: 7.8756e-04 - val_loss: 7.8923e-04\n","Epoch 14/25\n","133/133 [==============================] - 1s 10ms/step - loss: 7.8037e-04 - val_loss: 7.8388e-04\n","Epoch 15/25\n","133/133 [==============================] - 1s 9ms/step - loss: 7.7459e-04 - val_loss: 7.7634e-04\n","Epoch 16/25\n","133/133 [==============================] - 1s 10ms/step - loss: 7.6874e-04 - val_loss: 7.7286e-04\n","Epoch 17/25\n","133/133 [==============================] - 1s 10ms/step - loss: 7.6629e-04 - val_loss: 7.7099e-04\n","Epoch 18/25\n","133/133 [==============================] - 1s 10ms/step - loss: 7.6476e-04 - val_loss: 7.6971e-04\n","Epoch 19/25\n","133/133 [==============================] - 1s 9ms/step - loss: 7.6357e-04 - val_loss: 7.6861e-04\n","Epoch 20/25\n","133/133 [==============================] - 1s 6ms/step - loss: 7.6257e-04 - val_loss: 7.6764e-04\n","Epoch 21/25\n","133/133 [==============================] - 1s 5ms/step - loss: 7.6178e-04 - val_loss: 7.6691e-04\n","Epoch 22/25\n","133/133 [==============================] - 1s 5ms/step - loss: 7.6109e-04 - val_loss: 7.6622e-04\n","Epoch 23/25\n","133/133 [==============================] - 1s 4ms/step - loss: 7.6037e-04 - val_loss: 7.6547e-04\n","Epoch 24/25\n","133/133 [==============================] - 1s 5ms/step - loss: 7.5973e-04 - val_loss: 7.6479e-04\n","Epoch 25/25\n","133/133 [==============================] - 1s 4ms/step - loss: 7.5911e-04 - val_loss: 7.6421e-04\n","1329/1329 [==============================] - 2s 1ms/step\n","30.15521764755249\n"]}],"source":["# final_embeddings_numpy = aggregated_embeddings.detach().numpy()\n","from keras.layers import Input, Dense\n","from keras.models import Model\n","import time\n","setup_seed(42)\n","\n","start_time = time.time()\n","\n","# Define the size of our embeddings\n","input_dim = final_embeddings_numpy.shape[1]  # embedding_dimension\n","encoding_dim = 100 # or choose based on your dataset\n","\n","# Define the input layer\n","input_layer = Input(shape=(input_dim,))\n","\n","# Encoder\n","encoded = Dense(encoding_dim, activation='relu')(input_layer)\n","\n","# Decoder\n","decoded = Dense(input_dim, activation='sigmoid')(encoded)\n","\n","# Autoencoder\n","autoencoder = Model(input_layer, decoded)\n","\n","# Compile the model\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","setup_seed(42)\n","\n","\n","# Split the data\n","X_train, X_val = train_test_split(final_embeddings_numpy, test_size=0.2, random_state=42)\n","\n","\n","autoencoder.fit(X_train, X_train,\n","                epochs=25,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(X_val, X_val))\n","\n","# Reconstruct embeddings\n","setup_seed(42)\n","\n","reconstructed_embeddings = autoencoder.predict(final_embeddings_numpy)\n","\n","# Calculate mean squared error (MSE) as reconstruction error\n","reconstruction_error = np.mean(np.power(final_embeddings_numpy - reconstructed_embeddings, 2), axis=1)\n","\n","threshold = np.mean(reconstruction_error) + np.std(reconstruction_error)\n","# Flag embeddings with errors above the threshold as anomalies\n","anomalies = reconstruction_error > threshold\n","\n","print(time.time() - start_time)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100,"status":"ok","timestamp":1711772030095,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"AVzi_sxTjtZC","outputId":"9646bcdb-f556-4c43-cc15-5e4aad5b29a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["ROC Score: 0.5000892547002318\n"]}],"source":["from pygod.metric import eval_roc_auc, eval_f1\n","# f1_score = eval_f1(y_values, anomalies)\n","# print('F1 Score:', f1_score)\n","roc_score = eval_roc_auc(y_values, reconstruction_error)\n","print('ROC Score:', roc_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1711770499023,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"66kqovVqseR4","outputId":"c1874254-32d2-4be2-925a-695d48797297"},"outputs":[],"source":["from pygod.metric import eval_roc_auc, eval_f1\n","# f1_score = eval_f1(y_values, anomalies)\n","# print('F1 Score:', f1_score)\n","roc_score = eval_roc_auc(y_values, reconstruction_error)\n","print('ROC Score:', roc_score)"]},{"cell_type":"markdown","metadata":{"id":"7GPWXj36t7BW"},"source":["## BOND - DgraphFin"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24265966,"status":"ok","timestamp":1712232509044,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"HJPb4tWEjwlB","outputId":"9f6f46c5-9e18-48c9-bac7-3a8f84ac589a"},"outputs":[],"source":["setup_seed(42)\n","import time\n","\n","print('dgraphFin')\n","\n","roc_scores, pred, prob, timing, memory_consumption = bond_pipeline(reindexed_snapshots[-1])\n","\n","filename = 'data/dgraph_bond_results.pkl'\n","\n","my_dict = {'roc_scores': roc_scores, 'pred': pred, 'prob': prob, 'timing': timing, 'memory_consumption': memory_consumption}\n","my_dict['y_true'] = y_values\n","\n","with open(filename, 'wb') as file:\n","    pickle.dump(my_dict, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aFgpw2xjrY5f"},"outputs":[],"source":["dgraph['roc_scores']['OCGNN']=dgraph['roc_scores']['AnomalyDAE']\n","filename = 'data/dgraph_bond_results.pkl'\n","\n","with open(filename, 'wb') as file:\n","    pickle.dump(dgraph, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"elapsed":17,"status":"error","timestamp":1712232509146,"user":{"displayName":"Samir Abdaljalil","userId":"12821206870783737575"},"user_tz":300},"id":"7mCyATMci6H5","outputId":"a9063ea6-7b8d-48ee-8457-7ed3f18cb9e2"},"outputs":[],"source":["algorithm = Radar()\n","algorithm.fit(reindexed_snapshots[-1])\n","pred, score, prob = algorithm.predict(reindexed_snapshots[-1], return_pred=True, return_score=True, return_prob=True, return_conf=False)\n","roc = eval_roc_auc(y_values, score)\n","dgraph['pred']['Radar'] = pred\n","dgraph['score']['Radar'] = score\n","dgraph['prob']['Radar'] = prob\n","dgraph['roc_scores']['Radar'] = roc\n","\n","filename = 'data/dgraph_bond_results.pkl'\n","\n","with open(filename, 'wb') as file:\n","    pickle.dump(my_dict, file)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lpAPZIHwuED6","outputId":"61ed6583-f62b-48ba-f775-089076dde7ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["dgraphFin\n"]}],"source":["setup_seed(42)\n","import time\n","\n","print('dgraphFin')\n","roc_scores, timing, memory_consumption = bond_pipeline(reindexed_snapshots[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uJmcpE7GvmZJ"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["Kd-siFGp8tTd","Y95F6TOW6Pkb","VxfIqfy36Ud8","w7WFz_OZQRQ8","Vw1DjbsSSiTo","ud2yoG3ITczx","k8-5eQ3X92if","mC57hKsPNb7q","YxrmpeUz_l_B","QS_oYTVmEj3j","aT0zpPSnJ7Yp","PxCgXAsH5nj0"],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
